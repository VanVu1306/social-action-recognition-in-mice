{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e281d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:12.719051Z",
     "iopub.status.busy": "2025-12-05T13:58:12.718857Z",
     "iopub.status.idle": "2025-12-05T13:58:30.065592Z",
     "shell.execute_reply": "2025-12-05T13:58:30.064765Z"
    },
    "papermill": {
     "duration": 17.353482,
     "end_time": "2025-12-05T13:58:30.066915",
     "exception": false,
     "start_time": "2025-12-05T13:58:12.713433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "HARDWARE CHECK\n",
      "============================================================\n",
      "GPU Available: True\n",
      "GPU Name: Tesla T4\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import json, ast\n",
    "from sklearn.base import clone, ClassifierMixin, BaseEstimator\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os, math\n",
    "import gc\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Hardware check\n",
    "import torch\n",
    "print(\"=\"*60)\n",
    "print(\"HARDWARE CHECK\")\n",
    "print(\"=\"*60)\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5582691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.076908Z",
     "iopub.status.busy": "2025-12-05T13:58:30.076160Z",
     "iopub.status.idle": "2025-12-05T13:58:30.082137Z",
     "shell.execute_reply": "2025-12-05T13:58:30.081620Z"
    },
    "papermill": {
     "duration": 0.011756,
     "end_time": "2025-12-05T13:58:30.083140",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.071384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # mode = \"validate\"\n",
    "    mode = \"submit\"\n",
    "\n",
    "    model_save_dir = \"/kaggle/working\"\n",
    "    # model_save_dir = \"D:/UET/ML/mouse_behavior/social-action-recognition-in-mice\"\n",
    "\n",
    "    train_csv_path = \"/kaggle/input/MABe-mouse-behavior-detection/train.csv\" \n",
    "    test_csv_path = \"/kaggle/input/MABe-mouse-behavior-detection/test.csv\"\n",
    "    train_annotation_path = \"/kaggle/input/MABe-mouse-behavior-detection/train_annotation\"\n",
    "    train_tracking_path = \"/kaggle/input/MABe-mouse-behavior-detection/train_tracking\"\n",
    "    test_tracking_path = \"/kaggle/input/MABe-mouse-behavior-detection/test_tracking\"\n",
    "\n",
    "    # train_csv_path = \"D:/UET/ML/mouse_behavior/data/train.csv\" \n",
    "    # test_csv_path = \"D:/UET/ML/mouse_behavior/data/test.csv\"\n",
    "    # train_annotation_path = \"D:/UET/ML/mouse_behavior/data/train_annotation\"\n",
    "    # train_tracking_path = \"D:/UET/ML/mouse_behavior/data/train_tracking\"\n",
    "    # test_tracking_path = \"D:/UET/ML/mouse_behavior/data/test_tracking\"\n",
    "\n",
    "    drop_body_parts =  [\n",
    "        'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', \n",
    "        'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', \n",
    "        'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint'\n",
    "    ]\n",
    "\n",
    "    # Threshold range: typically 0.20-0.40, with 0.27 as a good starting point\n",
    "    # Higher thresholds = fewer false positives, more false negatives\n",
    "    # Lower thresholds = more false positives, fewer false negatives\n",
    "    action_thresholds = {\n",
    "        \"default\": 0.27,           # Global fallback threshold\n",
    "        \"single_default\": 0.26,    # Default for single mouse behaviors- lowered to improve recall\n",
    "        \"pair_default\": 0.28,      # Default for pair behaviors - slightly higher to reduce false positives\n",
    "        \"single\": {\n",
    "            \"rear\": 0.30,          # Higher threshold - distinctive behavior, reduce false positives\n",
    "            \"groom\": 0.28,         # Slightly higher - common behavior, needs good confidence\n",
    "            \"sniff\": 0.25,         # Lower threshold - subtle behavior, improve recall\n",
    "            \"dig\": 0.29,           # Higher threshold - distinctive behavior\n",
    "            \"eat\": 0.27,           # Standard threshold - balanced precision/recall\n",
    "            \"drink\": 0.27,         # Standard threshold - balanced precision/recall\n",
    "            \"sleep\": 0.24,         # Lower threshold - rare but important, improve recall\n",
    "        },\n",
    "        \"pair\": {\n",
    "            \"attack\": 0.24,        # Lower threshold - rare but critical behavior, maximize recall\n",
    "            \"mount\": 0.28,         # Higher threshold - distinctive behavior, reduce false positives\n",
    "            \"sniff\": 0.26,         # Lower threshold - subtle social behavior, improve recall\n",
    "            \"groom\": 0.27,         # Standard threshold - balanced precision/recall\n",
    "            \"chase\": 0.25,         # Lower threshold - important social behavior, improve recall\n",
    "            \"follow\": 0.26,        # Lower threshold - subtle behavior, improve recall\n",
    "            \"approach\": 0.27,      # Standard threshold - balanced precision/recall\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e53597",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.091411Z",
     "iopub.status.busy": "2025-12-05T13:58:30.091212Z",
     "iopub.status.idle": "2025-12-05T13:58:30.200215Z",
     "shell.execute_reply": "2025-12-05T13:58:30.199678Z"
    },
    "papermill": {
     "duration": 0.114496,
     "end_time": "2025-12-05T13:58:30.201456",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.086960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(CFG.train_csv_path) \n",
    "test_csv = pd.read_csv(CFG.test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42aebad1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.210639Z",
     "iopub.status.busy": "2025-12-05T13:58:30.210381Z",
     "iopub.status.idle": "2025-12-05T13:58:30.240188Z",
     "shell.execute_reply": "2025-12-05T13:58:30.239441Z"
    },
    "papermill": {
     "duration": 0.035692,
     "end_time": "2025-12-05T13:58:30.241284",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.205592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_lab = train_csv[\"lab_id\"].str.startswith(\"MABe22\")\n",
    "mask_behavior = train_csv[\"behaviors_labeled\"].isna() | (train_csv[\"behaviors_labeled\"].str.strip() == \"\")\n",
    "mask_drop = mask_lab | mask_behavior\n",
    "\n",
    "train = train_csv[~mask_drop]\n",
    "body_parts_list = list(np.unique(train.body_parts_tracked))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3530a5f",
   "metadata": {
    "papermill": {
     "duration": 0.003671,
     "end_time": "2025-12-05T13:58:30.248695",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.245024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca6739f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.257162Z",
     "iopub.status.busy": "2025-12-05T13:58:30.256937Z",
     "iopub.status.idle": "2025-12-05T13:58:30.270585Z",
     "shell.execute_reply": "2025-12-05T13:58:30.270037Z"
    },
    "papermill": {
     "duration": 0.019207,
     "end_time": "2025-12-05T13:58:30.271523",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.252316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_mouse_data(datasubset, mode, traintest_directory=None, generate_single=True, generate_pair=True):\n",
    "    \"\"\"\n",
    "    Yields:\n",
    "        (mode, X, meta, y)\n",
    "        mode: \"single\" hoặc \"pair\"\n",
    "        X: raw features DataFrame\n",
    "        meta: metadata DataFrame\n",
    "        y: labels (đối với train mode) hoặc action list (đối với test mode)\n",
    "    \"\"\"\n",
    "\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{mode}_tracking\"\n",
    "        # traintest_directory = f\"D:/UET/ML/mouse_behavior/data/{mode}_tracking\"\n",
    "\n",
    "    for idx, row in datasubset.iterrows():\n",
    "        lab_id = row.lab_id\n",
    "        video_id = row.video_id\n",
    "        pix_per_cm = row.pix_per_cm_approx\n",
    "        fps = row.frames_per_second\n",
    "\n",
    "        # Bỏ qua MABe22 labs hoặc missing behaviors\n",
    "        if lab_id.startswith(\"MABe22\"):\n",
    "            continue\n",
    "        if mode == \"train\" and (pd.isna(row.behaviors_labeled) or str(row.behaviors_labeled).strip() == \"\"):\n",
    "            continue\n",
    "\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "\n",
    "        # Load tracking\n",
    "        vid = pd.read_parquet(path)\n",
    "\n",
    "        # Bỏ bớt bodyparts\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            vid = vid[~vid.bodypart.isin(CFG.drop_body_parts)]\n",
    "\n",
    "        pvid = vid.pivot(\n",
    "            index=\"video_frame\",\n",
    "            columns=[\"mouse_id\", \"bodypart\"],\n",
    "            values=[\"x\", \"y\"]\n",
    "        )\n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n",
    "        pvid /= pix_per_cm\n",
    "\n",
    "        del vid\n",
    "        gc.collect()\n",
    "\n",
    "        mouse_ids = pvid.columns.get_level_values(0).unique().tolist()\n",
    "\n",
    "        # Tìm behaviors tracked trong CSV file\n",
    "        vid_behaviors = json.loads(row.behaviors_labeled)\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=[\"agent\", \"target\", \"action\"])\n",
    "\n",
    "        # Load annotation (đối với training mode)\n",
    "        if mode == \"train\":\n",
    "            try: \n",
    "                annot = pd.read_parquet(path.replace(\"train_tracking\", \"train_annotation\"))\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "        else:\n",
    "            annot = None\n",
    "\n",
    "\n",
    "        # Build data cho single mouse \n",
    "        if generate_single:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\")\n",
    "\n",
    "            for mouse_id_str in vid_behaviors_subset.agent.unique():\n",
    "                try:\n",
    "                    mouse_id = int(mouse_id_str.replace(\"mouse\", \"\"))\n",
    "                \n",
    "                    if mouse_id not in mouse_ids:\n",
    "                        continue\n",
    "\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n",
    "\n",
    "                    # Single mouse raw features - toạ độ bodyparts\n",
    "                    single_mouse = pvid.loc[:, mouse_id]\n",
    "                    assert len(single_mouse) == len(pvid)\n",
    "                \n",
    "                    # Single mouse meta data\n",
    "                    meta = pd.DataFrame({\n",
    "                        \"video_id\": video_id,\n",
    "                        \"agent_id\": mouse_id_str,\n",
    "                        \"target_id\": \"self\",\n",
    "                        \"video_frame\": single_mouse.index,\n",
    "                        \"frames_per_second\": fps\n",
    "                    })\n",
    "\n",
    "                    # Single mouse labels\n",
    "                    if mode == \"train\":\n",
    "                        labels = pd.DataFrame(0.0, index=single_mouse.index, columns=vid_agent_actions)\n",
    "                    \n",
    "                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
    "\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            labels.loc[annot_row[\"start_frame\"]:annot_row[\"stop_frame\"], annot_row.action] = 1.0\n",
    "                        yield \"single\", single_mouse, meta, labels\n",
    "                    else:\n",
    "                        yield \"single\", single_mouse, meta, vid_agent_actions\n",
    "\n",
    "                except (KeyError, ValueError):\n",
    "                    pass\n",
    "\n",
    "        # Build data cho mouse pair\n",
    "        if generate_pair:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n",
    "\n",
    "            if len(vid_behaviors_subset) > 0:\n",
    "                for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values(\"mouse_id\")), 2):\n",
    "                    agent_str = f\"mouse{agent}\"\n",
    "                    target_str = f\"mouse{target}\"\n",
    "\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n",
    "\n",
    "                    if len(vid_agent_actions) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Mouse pair raw features - toạ độ bodyparts của cặp chuột\n",
    "                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=[\"A\", \"B\"])  # Raw coordinates\n",
    "                    assert len(mouse_pair) == len(pvid)\n",
    "\n",
    "                    # Mouse pair meta data\n",
    "                    meta = pd.DataFrame({\n",
    "                        \"video_id\": video_id,\n",
    "                        \"agent_id\": agent_str,\n",
    "                        \"target_id\": target_str,\n",
    "                        \"video_frame\": pvid.index,\n",
    "                        \"frames_per_second\": fps\n",
    "                    })\n",
    "\n",
    "                    # Mouse pair labels\n",
    "                    if mode == \"train\":\n",
    "                        labels = pd.DataFrame(0.0, index=pvid.index, columns=vid_agent_actions)\n",
    "                    \n",
    "                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n",
    "\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            labels.loc[annot_row[\"start_frame\"]:annot_row[\"stop_frame\"], annot_row.action] = 1.0\n",
    "                        yield \"pair\", mouse_pair, meta, labels\n",
    "                    else:\n",
    "                        yield \"pair\", mouse_pair, meta, vid_agent_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac0c838",
   "metadata": {
    "papermill": {
     "duration": 0.003528,
     "end_time": "2025-12-05T13:58:30.278617",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.275089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f529cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.286601Z",
     "iopub.status.busy": "2025-12-05T13:58:30.286390Z",
     "iopub.status.idle": "2025-12-05T13:58:30.290774Z",
     "shell.execute_reply": "2025-12-05T13:58:30.290097Z"
    },
    "papermill": {
     "duration": 0.0096,
     "end_time": "2025-12-05T13:58:30.291891",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.282291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _fps_from_meta(meta_df, fallback_lookup, default_fps=30.0):\n",
    "    \"\"\"Get FPS with proper fallback chain\"\"\"\n",
    "    if \"frames_per_second\" in meta_df.columns:\n",
    "        fps_val = meta_df[\"frames_per_second\"].iloc[0]\n",
    "        if pd.notnull(fps_val) and fps_val > 0:\n",
    "            return float(fps_val)\n",
    "    \n",
    "    vid = meta_df[\"video_id\"].iloc[0]\n",
    "    if vid in fallback_lookup:\n",
    "        return float(fallback_lookup[vid])\n",
    "    \n",
    "    return default_fps\n",
    "\n",
    "def _scale(n_frames_at_30fps, fps, ref=30.0):\n",
    "    \"\"\"Scale window size by FPS\"\"\"\n",
    "    return max(1, int(round(n_frames_at_30fps * float(fps) / ref)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78e90b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.300393Z",
     "iopub.status.busy": "2025-12-05T13:58:30.300175Z",
     "iopub.status.idle": "2025-12-05T13:58:30.313025Z",
     "shell.execute_reply": "2025-12-05T13:58:30.312489Z"
    },
    "papermill": {
     "duration": 0.018525,
     "end_time": "2025-12-05T13:58:30.314053",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.295528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_centers(df):\n",
    "    \"\"\"\n",
    "    Đảm bảo \"body_center\" tồn tại với mọi chuột hoặc bodyparts combination.\n",
    "    Xử lý cả cột 2-level (bodypart, coord) (từng chuột) và 3-level (mouse_id, bodypart, coord) (cặp chuột).\n",
    "    \n",
    "    Fallback logic:\n",
    "    1. Nếu nose và tail_base tồn tại → midpoint(nose, tail_base)\n",
    "    2. Else if head và tail_base tồn tại → midpoint(head, tail_base)\n",
    "    3. Else if chỉ tail_base tồn tại → use tail_base\n",
    "    4. Else → không tính được body_center\n",
    "    \"\"\"\n",
    "    cols = df.columns\n",
    "\n",
    "    # Cột 2-level (bodypart, coord)\n",
    "    if cols.nlevels == 2:\n",
    "        if (\"body_center\", \"x\") not in df.columns or (\"body_center\", \"y\") not in df.columns:\n",
    "            if (\"nose\", \"x\") in df.columns and (\"tail_base\", \"x\") in df.columns:\n",
    "                df[(\"body_center\", \"x\")] = (df[(\"nose\", \"x\")] + df[(\"tail_base\", \"x\")]) / 2\n",
    "                df[(\"body_center\", \"y\")] = (df[(\"nose\", \"y\")] + df[(\"tail_base\", \"y\")]) / 2\n",
    "            elif (\"head\", \"x\") in df.columns and (\"tail_base\", \"x\") in df.columns:\n",
    "                df[(\"body_center\", \"x\")] = (df[(\"head\", \"x\")] + df[(\"tail_base\", \"x\")]) / 2\n",
    "                df[(\"body_center\", \"y\")] = (df[(\"head\", \"y\")] + df[(\"tail_base\", \"y\")]) / 2\n",
    "            elif (\"tail_base\", \"x\") in df.columns:\n",
    "                df[(\"body_center\", \"x\")] = df[(\"tail_base\", \"x\")]\n",
    "                df[(\"body_center\", \"y\")] = df[(\"tail_base\", \"y\")]\n",
    "            else:\n",
    "                # no valid bodyparts → fill NaN\n",
    "                df[(\"body_center\", \"x\")] = np.nan\n",
    "                df[(\"body_center\", \"y\")] = np.nan\n",
    "\n",
    "    # Cột 3-level (mouse_id, bodypart, coord)\n",
    "    elif cols.nlevels == 3:\n",
    "        mice = sorted(list(set(c[0] for c in cols)))\n",
    "\n",
    "        for m in mice:\n",
    "            has_body_center = ((m, \"body_center\", \"x\") in cols) and ((m, \"body_center\", \"y\") in cols)\n",
    "            if not has_body_center:\n",
    "                if ((m, \"nose\", \"x\") in cols) and ((m, \"tail_base\", \"x\") in cols):\n",
    "                    df[(m, \"body_center\", \"x\")] = (df[(m, \"nose\", \"x\")] + df[(m, \"tail_base\", \"x\")]) / 2\n",
    "                    df[(m, \"body_center\", \"y\")] = (df[(m, \"nose\", \"y\")] + df[(m, \"tail_base\", \"y\")]) / 2\n",
    "                elif ((m, \"head\", \"x\") in cols) and ((m, \"tail_base\", \"x\") in cols):\n",
    "                    df[(m, \"body_center\", \"x\")] = (df[(m, \"head\", \"x\")] + df[(m, \"tail_base\", \"x\")]) / 2\n",
    "                    df[(m, \"body_center\", \"y\")] = (df[(m, \"head\", \"y\")] + df[(m, \"tail_base\", \"y\")]) / 2\n",
    "                elif ((m, \"tail_base\", \"x\") in cols):\n",
    "                    df[(m, \"body_center\", \"x\")] = df[(m, \"tail_base\", \"x\")]\n",
    "                    df[(m, \"body_center\", \"y\")] = df[(m, \"tail_base\", \"y\")]\n",
    "                else:\n",
    "                    df[(m, \"body_center\", \"x\")] = np.nan\n",
    "                    df[(m, \"body_center\", \"y\")] = np.nan\n",
    "    return df\n",
    "\n",
    "def calculate_speed_lag(df, part, fps, lag=10, mouse=None):\n",
    "    cols = df.columns\n",
    "    if mouse is not None:\n",
    "        x = df[(mouse, part, \"x\")]\n",
    "        y = df[(mouse, part, \"y\")]\n",
    "    else:\n",
    "        x = df[(part, \"x\")]\n",
    "        y = df[(part, \"y\")]\n",
    "\n",
    "    if x.isna().all() or y.isna().all():\n",
    "        # all missing → return zeros\n",
    "        return pd.Series(0, index=df.index)\n",
    "\n",
    "    dx = x.diff(lag)\n",
    "    dy = y.diff(lag)\n",
    "    speed = np.sqrt(dx**2 + dy**2) * fps\n",
    "    return speed.fillna(0)\n",
    "\n",
    "# Tính các thống kê của 1 đại lượng theo nhiều cửa sổ thời gian\n",
    "def calculate_window_stats(df, metric, name, fps, scales=[30, 90]):\n",
    "    \"\"\"\n",
    "    Thêm rolling statistics cho bất kỳ series nào.\n",
    "    \n",
    "    metric : pd.Series (ví dụ speed, distance, curvature...)\n",
    "    fps    : frames_per_second\n",
    "    scales : list window sizes quy đổi theo 30fps → mặc định [30, 90] = short và long term\n",
    "    \"\"\"\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    for scale in scales:\n",
    "        ws = _scale(scale, fps)\n",
    "        roll = metric.rolling(ws, min_periods=max(1, ws//4))\n",
    "\n",
    "        res[f\"{name}_mean_{scale}\"] = roll.mean()\n",
    "        res[f\"{name}_std_{scale}\"]  = roll.std()\n",
    "        res[f\"{name}_min_{scale}\"]  = roll.min()\n",
    "        res[f\"{name}_max_{scale}\"]  = roll.max()\n",
    "\n",
    "    return res\n",
    "\n",
    "# Tính onset - offset features: Onset = thay đổi từ {lag} frame trước -> frame hiện tại. Offset = thay đổi từ frame hiện tại -> {lag} frame tương lai\n",
    "def add_onset_offset(metric: pd.Series, name: str, lag_list=[3, 5]):\n",
    "    out = {}\n",
    "    for lag in lag_list:\n",
    "        out[f\"{name}_onset_lag{lag}\"]  = metric - metric.shift(lag)\n",
    "        out[f\"{name}_offset_lag{lag}\"] = metric.shift(-lag) - metric\n",
    "    return pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e0464dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.322417Z",
     "iopub.status.busy": "2025-12-05T13:58:30.322210Z",
     "iopub.status.idle": "2025-12-05T13:58:30.344876Z",
     "shell.execute_reply": "2025-12-05T13:58:30.344283Z"
    },
    "papermill": {
     "duration": 0.028212,
     "end_time": "2025-12-05T13:58:30.345958",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.317746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_single_features(single_mouse_df, body_parts_tracked, meta_fps):\n",
    "    single_mouse_df = calculate_centers(single_mouse_df)\n",
    "\n",
    "    # Get actual bodypart columns\n",
    "    available_body_parts = single_mouse_df.columns.get_level_values(0).unique()\n",
    "    \n",
    "    # === Shape and Position Features ===\n",
    "    # Euclidean distances giữa các cặp bodyparts\n",
    "    X = pd.DataFrame({\n",
    "        f\"{p1}+{p2}\": np.sqrt(\n",
    "            (single_mouse_df[(p1, \"x\")] - single_mouse_df[(p2, \"x\")])**2 + \n",
    "            (single_mouse_df[(p1, \"y\")] - single_mouse_df[(p2, \"y\")])**2\n",
    "        )\n",
    "        for p1, p2 in itertools.combinations(body_parts_tracked, 2)\n",
    "        if p1 in available_body_parts and p2 in available_body_parts\n",
    "    })\n",
    "    \n",
    "    expected_cols = [f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)]\n",
    "    X = X.reindex(columns=expected_cols, copy=False)\n",
    "    \n",
    "    # Elongation (chỉ khi required bodyparts tồn tại)\n",
    "    if \"nose\" in available_body_parts and \"tail_base\" in available_body_parts and \"ear_left\" in available_body_parts and \"ear_right\" in available_body_parts:\n",
    "        X[\"elong\"] = X[\"nose+tail_base\"] / (X[\"ear_left+ear_right\"] + 1e-6)\n",
    "    else:\n",
    "        X[\"elong\"] = 0.0\n",
    "    \n",
    "    # Body angle (chỉ khi nose, tail_base, body_center tồn tại)\n",
    "    if all(bp in available_body_parts for bp in [\"nose\", \"tail_base\", \"body_center\"]):\n",
    "        v1_x = single_mouse_df[(\"nose\",\"x\")] - single_mouse_df[(\"body_center\",\"x\")]\n",
    "        v1_y = single_mouse_df[(\"nose\",\"y\")] - single_mouse_df[(\"body_center\",\"y\")]\n",
    "        v2_x = single_mouse_df[(\"tail_base\",\"x\")] - single_mouse_df[(\"body_center\",\"x\")]\n",
    "        v2_y = single_mouse_df[(\"tail_base\",\"y\")] - single_mouse_df[(\"body_center\",\"y\")]\n",
    "        X[\"body_angle\"] = (v1_x*v2_x + v1_y*v2_y) / (np.sqrt(v1_x**2+v1_y**2) * np.sqrt(v2_x**2+v2_y**2) + 1e-6)\n",
    "    else:\n",
    "        X[\"body_angle\"] = 0.0\n",
    "    \n",
    "    # === Movement Features: speed/accelerate/energy ===\n",
    "    if \"body_center\" in available_body_parts:\n",
    "        speed = np.sqrt(\n",
    "            single_mouse_df[(\"body_center\", \"x\")].diff()**2 +\n",
    "            single_mouse_df[(\"body_center\", \"y\")].diff()**2\n",
    "        )\n",
    "        X[\"speed\"] = speed\n",
    "        X[\"accelerate\"] = X[\"speed\"].diff().fillna(0)\n",
    "        X[\"energy\"] = (speed**2).rolling(window=5).sum().fillna(0) # intensity of movement\n",
    "    else:\n",
    "        X[\"speed\"] = 0.0\n",
    "        X[\"accelerate\"] = 0.0\n",
    "        X[\"energy\"] = 0.0\n",
    "    \n",
    "    # Đối với available bodyparts cụ thể\n",
    "    for p in [\"body_center\"]:\n",
    "        if p in available_body_parts:\n",
    "            # Speed lag features\n",
    "            lag_speed = calculate_speed_lag(single_mouse_df, p, fps=meta_fps)\n",
    "            X[f\"speed_{p}_lag_10\"] = lag_speed\n",
    "            X = pd.concat([X, add_onset_offset(lag_speed, f\"speed_{p}\")], axis=1)\n",
    "            \n",
    "            # Rolling stats\n",
    "            speed = np.sqrt(single_mouse_df[(p, \"x\")].diff()**2 + single_mouse_df[(p, \"y\")].diff()**2) * float(meta_fps)\n",
    "            res = calculate_window_stats(single_mouse_df, speed, f\"speed_{p}\", fps=meta_fps)\n",
    "            X = pd.concat([X, res], axis=1)\n",
    "\n",
    "            # Curvature\n",
    "            lag = _scale(10, meta_fps)\n",
    "            shifted_x = single_mouse_df[(p,\"x\")].shift(lag)\n",
    "            shifted_y = single_mouse_df[(p,\"y\")].shift(lag)\n",
    "            curv = np.sqrt((shifted_x - single_mouse_df[(p,\"x\")])**2 + \n",
    "                                                    (shifted_y - single_mouse_df[(p,\"y\")])**2)\n",
    "            X[f\"curvature_{p}_lag_{lag}\"] = curv\n",
    "            X = pd.concat([X, add_onset_offset(curv, f\"curvature_{p}\")], axis=1)\n",
    "\n",
    "                \n",
    "        else:\n",
    "            # Dummy columns\n",
    "            X[f\"speed_{p}_lag_10\"] = 0.0\n",
    "            for lag in [3, 5]:\n",
    "                X[f\"speed{p}_onset_lag{lag}\"]  = 0.0\n",
    "                X[f\"speed_{p}_offset_lag{lag}\"] = 0.0\n",
    "            \n",
    "            \n",
    "            for scale in [30, 90]:\n",
    "                X[f\"speed_{p}_mean_{scale}\"] = 0.0\n",
    "                X[f\"speed_{p}_std_{scale}\"] = 0.0\n",
    "                X[f\"speed_{p}_min_{scale}\"] = 0.0\n",
    "                X[f\"speed_{p}_max_{scale}\"] = 0.0\n",
    "                \n",
    "            lag = _scale(10, meta_fps)\n",
    "            X[f\"curvature_{p}_lag_{lag}\"] = 0.0\n",
    "\n",
    "            for lag in [3, 5]:\n",
    "                X[f\"curvature_{p}_onset_lag{lag}\"]  = 0.0\n",
    "                X[f\"curvature_{p}_offset_lag{lag}\"] = 0.0\n",
    "    \n",
    "    return X.astype(np.float32, copy=False).fillna(0)\n",
    "\n",
    "\n",
    "def build_pair_features(mouse_pair_df, body_parts_tracked, meta_fps):\n",
    "    mouse_pair_df = calculate_centers(mouse_pair_df)\n",
    "    \n",
    "    # Get bodyparts for both mice\n",
    "    avail_A = mouse_pair_df[\"A\"].columns.get_level_values(0).unique()\n",
    "    avail_B = mouse_pair_df[\"B\"].columns.get_level_values(0).unique()\n",
    "    \n",
    "    # Pairwise distances\n",
    "    X = pd.DataFrame({\n",
    "        f\"A_{p1}+B_{p2}\": np.sqrt(\n",
    "            (mouse_pair_df[(\"A\", p1, \"x\")] - mouse_pair_df[(\"B\", p2, \"x\")])**2 +\n",
    "            (mouse_pair_df[(\"A\", p1, \"y\")] - mouse_pair_df[(\"B\", p2, \"y\")])**2\n",
    "        )\n",
    "        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n",
    "        if p1 in avail_A and p2 in avail_B\n",
    "    })\n",
    "    \n",
    "    expected_cols = [f\"A_{p1}+B_{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)]\n",
    "    X = X.reindex(columns=expected_cols, copy=False)\n",
    "    \n",
    "    # Relative orientation (chỉ khi nose and tail_base tồn tại ở cả 2 chuột)\n",
    "    if all(bp in avail_A for bp in [\"nose\",\"tail_base\"]) and all(bp in avail_B for bp in [\"nose\",\"tail_base\"]):\n",
    "        vec_A_x = mouse_pair_df[(\"A\", \"nose\", \"x\")] - mouse_pair_df[(\"A\", \"tail_base\", \"x\")]\n",
    "        vec_A_y = mouse_pair_df[(\"A\", \"nose\", \"y\")] - mouse_pair_df[(\"A\", \"tail_base\", \"y\")]\n",
    "        vec_B_x = mouse_pair_df[(\"B\", \"nose\", \"x\")] - mouse_pair_df[(\"B\", \"tail_base\", \"x\")]\n",
    "        vec_B_y = mouse_pair_df[(\"B\", \"nose\", \"y\")] - mouse_pair_df[(\"B\", \"tail_base\", \"y\")]\n",
    "        X[\"relative_orientation\"] = (vec_A_x*vec_B_x + vec_A_y*vec_B_y) / (\n",
    "            np.sqrt(vec_A_x**2 + vec_A_y**2) * np.sqrt(vec_B_x**2 + vec_B_y**2) + 1e-6\n",
    "        )\n",
    "    elif all(bp in avail_A for bp in [\"head\",\"tail_base\"]) and all(bp in avail_B for bp in [\"head\",\"tail_base\"]):\n",
    "        vec_A_x = mouse_pair_df[(\"A\", \"head\", \"x\")] - mouse_pair_df[(\"A\", \"tail_base\", \"x\")]\n",
    "        vec_A_y = mouse_pair_df[(\"A\", \"head\", \"y\")] - mouse_pair_df[(\"A\", \"tail_base\", \"y\")]\n",
    "        vec_B_x = mouse_pair_df[(\"B\", \"head\", \"x\")] - mouse_pair_df[(\"B\", \"tail_base\", \"x\")]\n",
    "        vec_B_y = mouse_pair_df[(\"B\", \"head\", \"y\")] - mouse_pair_df[(\"B\", \"tail_base\", \"y\")]\n",
    "        X[\"relative_orientation\"] = (vec_A_x*vec_B_x + vec_A_y*vec_B_y) / (\n",
    "            np.sqrt(vec_A_x**2 + vec_A_y**2) * np.sqrt(vec_B_x**2 + vec_B_y**2) + 1e-6\n",
    "        )\n",
    "    else:\n",
    "        X[\"relative_orientation\"] = 0.0\n",
    "    \n",
    "    # Center distance và approach\n",
    "    if \"body_center\" in avail_A and \"body_center\" in avail_B:\n",
    "        dist_center = np.sqrt(\n",
    "            (mouse_pair_df[(\"A\", \"body_center\", \"x\")] - mouse_pair_df[(\"B\", \"body_center\", \"x\")])**2 +\n",
    "            (mouse_pair_df[(\"A\", \"body_center\", \"y\")] - mouse_pair_df[(\"B\", \"body_center\", \"y\")])**2\n",
    "        )\n",
    "        X = pd.concat([X, add_onset_offset(dist_center, \"dist_center\")], axis=1)\n",
    "        \n",
    "        approach = dist_center.diff().fillna(0)\n",
    "        X[\"approach_A\"] = approach\n",
    "        X[\"approach_B\"] = approach\n",
    "        X = pd.concat([X, add_onset_offset(approach, \"approach\")], axis=1)\n",
    "        \n",
    "        # Relative center distance stats\n",
    "        res = calculate_window_stats(mouse_pair_df, dist_center**2, \"center_distance\", fps=meta_fps)\n",
    "        X = pd.concat([X, res], axis=1)\n",
    "        \n",
    "        # Relative speed\n",
    "        speed_A = calculate_speed_lag(mouse_pair_df, \"body_center\", meta_fps, mouse=\"A\")\n",
    "        speed_B = calculate_speed_lag(mouse_pair_df, \"body_center\", meta_fps, mouse=\"B\")\n",
    "        X[\"speed_A_lag_10\"] = speed_A\n",
    "        X[\"speed_B_lag_10\"] = speed_B\n",
    "        rel = (speed_A - speed_B).abs()\n",
    "        X[\"relative_speed_A_B_lag_10\"] = rel\n",
    "        X = pd.concat([X, add_onset_offset(rel, \"relative_speed\")], axis=1)\n",
    "\n",
    "        # Ngưỡng khoảng cách\n",
    "        thresholds = {\n",
    "            \"very_close\": 20,\n",
    "            \"close\": 40,\n",
    "            \"medium\": 60\n",
    "        }\n",
    "        X[\"very_close\"] = (dist_center < thresholds[\"very_close\"]).astype(float)\n",
    "        X[\"close\"] = ((dist_center >= thresholds[\"very_close\"]) & (dist_center < thresholds[\"close\"])).astype(float)\n",
    "        X[\"medium\"] = ((dist_center >= thresholds[\"close\"]) & (dist_center < thresholds[\"medium\"])).astype(float)\n",
    "        X[\"far\"] = (dist_center >= thresholds[\"medium\"]).astype(float)\n",
    "\n",
    "    else:\n",
    "        # Dummy columns\n",
    "        for lag in [3, 5]:\n",
    "            X[f\"dist_center_onset_lag{lag}\"]  = 0.0\n",
    "            X[f\"dist_center_offset_lag{lag}\"] = 0.0\n",
    "\n",
    "        X[\"approach_A\"] = 0.0\n",
    "        X[\"approach_B\"] = 0.0\n",
    "        for lag in [3, 5]:\n",
    "            X[f\"approach_onset_lag{lag}\"]  = 0.0\n",
    "            X[f\"approach_offset_lag{lag}\"] = 0.0\n",
    "        \n",
    "        for scale in [30, 90]:\n",
    "            X[f\"center_distance_mean_{scale}\"] = 0.0\n",
    "            X[f\"center_distance_std_{scale}\"] = 0.0\n",
    "            X[f\"center_distance_min_{scale}\"] = 0.0\n",
    "            X[f\"center_distance_max_{scale}\"] = 0.0\n",
    "        \n",
    "        X[\"speed_A_lag_10\"] = 0.0\n",
    "        X[\"speed_B_lag_10\"] = 0.0\n",
    "        X[\"relative_speed_A_B_lag_10\"] = 0.0\n",
    "        for lag in [3, 5]:\n",
    "            X[f\"relative_speed_onset_lag{lag}\"]  = 0.0\n",
    "            X[f\"relative_speed_offset_lag{lag}\"] = 0.0\n",
    "\n",
    "        X[\"very_close\"] = 0.0\n",
    "        X[\"close\"] = 0.0\n",
    "        X[\"medium\"] = 0.0\n",
    "        X[\"far\"] = 0.0   \n",
    "    \n",
    "    return X.astype(np.float32, copy=False).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c87485f",
   "metadata": {
    "papermill": {
     "duration": 0.003754,
     "end_time": "2025-12-05T13:58:30.353292",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.349538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1b3fb09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.361757Z",
     "iopub.status.busy": "2025-12-05T13:58:30.361539Z",
     "iopub.status.idle": "2025-12-05T13:58:30.371583Z",
     "shell.execute_reply": "2025-12-05T13:58:30.370939Z"
    },
    "papermill": {
     "duration": 0.01567,
     "end_time": "2025-12-05T13:58:30.372725",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.357055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StratifiedSubsetClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Wrapper class để subsamples data trước khi train\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator, n_samples=None):\n",
    "        self.estimator = estimator\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def _to_numpy(self, X):\n",
    "        try:\n",
    "            return X.to_numpy(np.float32, copy=False)\n",
    "        except AttributeError:\n",
    "            return np.asarray(X, dtype=np.float32)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_np = self._to_numpy(X)\n",
    "        y = np.asarray(y).ravel()\n",
    "\n",
    "        # Handle edge case: labels có thể là {0, 2} thay vì {0, 1}\n",
    "        uniq = np.unique(y[~pd.isna(y)])\n",
    "        if set(uniq.tolist()) == {0, 2}:\n",
    "            y = (y > 0).astype(np.int8)\n",
    "\n",
    "        # Nếu X < n_samples thì không cần Stratified Shuffle Split\n",
    "        if self.n_samples is None or len(X_np) <= int(self.n_samples):\n",
    "            self.estimator.fit(X_np, y)\n",
    "        else:\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, train_size=int(self.n_samples), random_state=42)\n",
    "            try:\n",
    "                idx, _ = next(sss.split(np.zeros_like(y), y)) # dummy X, để đảm bảo stratification trên label\n",
    "                self.estimator.fit(X_np[idx], y[idx])\n",
    "            except Exception as e:\n",
    "                if \"best_split_info_left_count\" in str(e):\n",
    "                    self.estimator.set_params(device_type=\"cpu\")\n",
    "                    self.estimator.fit(X_np[idx], y[idx])\n",
    "                else:\n",
    "                    # Fallback: simple step sampling\n",
    "                    step = max(len(X_np) // int(self.n_samples), 1)\n",
    "                    self.estimator.fit(X_np[::step], y[::step])\n",
    "\n",
    "        try:\n",
    "            self.classes_ = np.asarray(self.estimator.classes_)\n",
    "        except Exception:\n",
    "            self.classes_ = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_np = self._to_numpy(X)\n",
    "        try:\n",
    "            P = self.estimator.predict_proba(X_np)\n",
    "        except Exception:\n",
    "            # Handle single class case\n",
    "            if len(self.classes_) == 1:\n",
    "                n = len(X_np)\n",
    "                c = int(self.classes_[0])\n",
    "                if c == 1:\n",
    "                    return np.column_stack([np.zeros(n, dtype=np.float32), np.ones(n, dtype=np.float32)])\n",
    "                else:\n",
    "                    return np.column_stack([np.ones(n, dtype=np.float32), np.zeros(n, dtype=np.float32)])\n",
    "            return np.full((len(X_np), 2), 0.5, dtype=np.float32)\n",
    "\n",
    "        P = np.asarray(P)\n",
    "        if P.ndim == 1:\n",
    "            P1 = P.astype(np.float32)\n",
    "            return np.column_stack([1.0 - P1, P1])\n",
    "        if P.shape[1] == 1 and len(self.classes_) == 2:\n",
    "            P1 = P[:, 0].astype(np.float32)\n",
    "            return np.column_stack([1.0 - P1, P1])\n",
    "        return P\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_np = self._to_numpy(X)\n",
    "        try:\n",
    "            return self.estimator.predict(X_np)\n",
    "        except Exception:\n",
    "            return np.argmax(self.predict_proba(X_np), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37382af7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.380859Z",
     "iopub.status.busy": "2025-12-05T13:58:30.380673Z",
     "iopub.status.idle": "2025-12-05T13:58:30.385593Z",
     "shell.execute_reply": "2025-12-05T13:58:30.385104Z"
    },
    "papermill": {
     "duration": 0.010349,
     "end_time": "2025-12-05T13:58:30.386636",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.376287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_ensemble_models(mode=\"single\"):\n",
    "    \"\"\"\n",
    "    Ensemble đơn giản với 3-model ensemble\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    \n",
    "    # Check GPU availability\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "    \n",
    "    if mode == \"single\":\n",
    "        n_samples_base = 2_000_000\n",
    "    else:\n",
    "        n_samples_base = 900_000\n",
    "\n",
    "    # Model 1: LightGBM\n",
    "    # models.append(\n",
    "    #     StratifiedSubsetClassifier(\n",
    "    #         lgb.LGBMClassifier(\n",
    "    #             n_estimators=400,\n",
    "    #             learning_rate=0.07,\n",
    "    #             num_leaves=31,\n",
    "    #             subsample=0.8,\n",
    "    #             colsample_bytree=0.9,\n",
    "    #             device_type=\"gpu\" if gpu_available else \"cpu\",\n",
    "    #             verbose=-1,\n",
    "    #             random_state=42\n",
    "    #         ),\n",
    "    #         n_samples=int(n_samples_base / 1.3)\n",
    "    #     )\n",
    "    # )\n",
    "    \n",
    "    # Model 2: LightGBM\n",
    "    models.append(\n",
    "        StratifiedSubsetClassifier(\n",
    "            lgb.LGBMClassifier(\n",
    "                n_estimators=300,\n",
    "                learning_rate=0.1,\n",
    "                num_leaves=63,\n",
    "                max_depth=8,\n",
    "                device_type=\"gpu\" if gpu_available else \"cpu\",\n",
    "                verbose=-1,\n",
    "                random_state=42\n",
    "            ),\n",
    "            n_samples=int(n_samples_base)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Model 3: XGBoost\n",
    "    models.append(\n",
    "        StratifiedSubsetClassifier(\n",
    "            xgb.XGBClassifier(\n",
    "                n_estimators=400,\n",
    "                learning_rate=0.08,\n",
    "                max_depth=6,\n",
    "                tree_method=\"gpu_hist\" if gpu_available else \"hist\",\n",
    "                device=\"cuda\" if gpu_available else \"cpu\",\n",
    "                random_state=42\n",
    "            ),\n",
    "            n_samples=int(n_samples_base)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85b90dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.394991Z",
     "iopub.status.busy": "2025-12-05T13:58:30.394597Z",
     "iopub.status.idle": "2025-12-05T13:58:30.399886Z",
     "shell.execute_reply": "2025-12-05T13:58:30.399189Z"
    },
    "papermill": {
     "duration": 0.010659,
     "end_time": "2025-12-05T13:58:30.400964",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.390305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_threshold_map(thresholds, mode: str):\n",
    "    \"\"\"\n",
    "    Tạo 1 defaultdict có mode(single/pair)-aware và action-specific thresholds\n",
    "    \"\"\"\n",
    "    if isinstance(thresholds, dict):\n",
    "        # Kiểm tra mode-aware structure tồn tại\n",
    "        if (\"single\" in thresholds) or (\"pair\" in thresholds) or \\\n",
    "           (\"single_default\" in thresholds) or (\"pair_default\" in thresholds):\n",
    "            # Mode-aware thresholds\n",
    "            base_default = float(thresholds.get(\"default\", 0.27))\n",
    "            mode_default = float(thresholds.get(f\"{mode}_default\", base_default))\n",
    "            mode_overrides = thresholds.get(mode, {}) or {}\n",
    "            \n",
    "            out = defaultdict(lambda: mode_default)\n",
    "            out.update({str(k): float(v) for k, v in mode_overrides.items()})\n",
    "            return out\n",
    "        \n",
    "        # Plain per-action dict\n",
    "        out = defaultdict(lambda: float(thresholds.get(\"default\", 0.27)))\n",
    "        out.update({str(k): float(v) for k, v in thresholds.items() if k != \"default\"})\n",
    "        return out\n",
    "    \n",
    "    # Fallback: constant threshold\n",
    "    return defaultdict(lambda: 0.27)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e24ad6",
   "metadata": {
    "papermill": {
     "duration": 0.003541,
     "end_time": "2025-12-05T13:58:30.408218",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.404677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc1c1487",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.416252Z",
     "iopub.status.busy": "2025-12-05T13:58:30.416036Z",
     "iopub.status.idle": "2025-12-05T13:58:30.427124Z",
     "shell.execute_reply": "2025-12-05T13:58:30.426461Z"
    },
    "papermill": {
     "duration": 0.016505,
     "end_time": "2025-12-05T13:58:30.428231",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.411726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_actions_ensemble(X, models_dict, actions):\n",
    "    \"\"\"\n",
    "    Dự đoán nhiều action với ensemble models.\n",
    "    \n",
    "    Args:\n",
    "        X: feature DataFrame\n",
    "        models: dict of trained classifiers {action: model}\n",
    "        actions: danh sách actions để predict\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame với xác suất mỗi actions\n",
    "    \"\"\"\n",
    "    \n",
    "    proba_df = pd.DataFrame(index=X.index)\n",
    "    X_np = X.to_numpy(np.float32, copy=False)\n",
    "    \n",
    "    for action in actions:\n",
    "        if action not in models_dict:\n",
    "            # Action not trained in this section\n",
    "            proba_df[action] = 0.0\n",
    "            continue\n",
    "        \n",
    "        model_list = models_dict[action]\n",
    "        \n",
    "        try:\n",
    "            # Get predictions from all models in ensemble\n",
    "            probs_list = []\n",
    "            for model in model_list:\n",
    "                try:\n",
    "                    prob = model.predict_proba(X_np)[:, 1]\n",
    "                    probs_list.append(prob)\n",
    "                except Exception:\n",
    "                    pass\n",
    "            \n",
    "            if len(probs_list) > 0:\n",
    "                # Average ensemble predictions\n",
    "                proba_df[action] = np.mean(probs_list, axis=0)\n",
    "            else:\n",
    "                proba_df[action] = 0.0\n",
    "                \n",
    "        except Exception as e:\n",
    "            proba_df[action] = 0.0\n",
    "    \n",
    "    return proba_df\n",
    "\n",
    "\n",
    "def predict_multiclass_adaptive(pred, meta, action_thresholds):\n",
    "    \"\"\"\n",
    "    Đổi frame probabilities thành chuỗi frame có action đó\n",
    "    + Adaptive thresholding cho từng action + temporal smoothing\n",
    "    Args:\n",
    "        pred: DataFrame (num_frames, num_actions) with probabilities\n",
    "        meta: DataFrame with video_frame, agent_id, target_id\n",
    "        thresholds: dict of thresholds per action\n",
    "    Returns:\n",
    "        DataFrame with columns: video_id, agent_id, target_id, action, start_frame, stop_frame\n",
    "    \"\"\"\n",
    "    # Apply temporal smoothing\n",
    "    pred_smoothed = pred.rolling(window=5, min_periods=1, center=True).mean()\n",
    "\n",
    "    # Determine mode (single/pair)\n",
    "    mode = \"pair\"\n",
    "    try:\n",
    "        if \"target_id\" in meta.columns and meta[\"target_id\"].eq(\"self\").all():\n",
    "            mode = \"single\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Lấy action có xác suất cao nhất mỗi frame\n",
    "    ama = np.argmax(pred_smoothed.values, axis=1)\n",
    "\n",
    "    # Lấy threshold map cho mode tương ứng\n",
    "    th_map = select_threshold_map(action_thresholds, mode)\n",
    "\n",
    "    # Áp dụng thresholds\n",
    "    max_probs = pred_smoothed.max(axis=1).values\n",
    "    threshold_mask = np.zeros(len(pred_smoothed), dtype=bool)\n",
    "    \n",
    "    for i, action in enumerate(pred_smoothed.columns):\n",
    "        action_mask = (ama == i)\n",
    "        threshold = th_map[action]\n",
    "        threshold_mask |= (action_mask & (max_probs >= threshold))\n",
    "    ama = np.where(threshold_mask, ama, -1)\n",
    "    ama = pd.Series(ama, index=meta.video_frame.values)\n",
    "    \n",
    "    # Detect changes\n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "    mask = ama_changes.values >= 0\n",
    "    mask[-1] = False\n",
    "    \n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id': meta_changes[\"video_id\"].values[mask],\n",
    "        'agent_id': meta_changes[\"agent_id\"].values[mask],\n",
    "        'target_id': meta_changes[\"target_id\"].values[mask],\n",
    "        'action': pred.columns[ama_changes.values[mask]],\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame': ama_changes.index[1:][mask[:-1]]\n",
    "    })\n",
    "    \n",
    "    # Fix stop_frame với mỗi bộ video/agent/target\n",
    "    stop_video_id = meta_changes[\"video_id\"].values[1:][mask[:-1]]\n",
    "    stop_agent_id = meta_changes[\"agent_id\"].values[1:][mask[:-1]]\n",
    "    stop_target_id = meta_changes[\"target_id\"].values[1:][mask[:-1]]\n",
    "    \n",
    "    for i in range(len(submission_part)):\n",
    "        video_id = submission_part.video_id.iloc[i]\n",
    "        agent_id = submission_part.agent_id.iloc[i]\n",
    "        target_id = submission_part.target_id.iloc[i]\n",
    "        \n",
    "        if i < len(stop_video_id):\n",
    "            if stop_video_id[i] != video_id or stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n",
    "                new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "                submission_part.iat[i, submission_part.columns.get_loc(\"stop_frame\")] = new_stop_frame\n",
    "        else:\n",
    "            meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "            submission_part.iat[i, submission_part.columns.get_loc(\"stop_frame\")] = new_stop_frame\n",
    "    \n",
    "    # Lọc events rất ngắn (nhiễu)\n",
    "    duration = submission_part.stop_frame - submission_part.start_frame\n",
    "    submission_part = submission_part[duration >= 3].reset_index(drop=True)\n",
    "    \n",
    "    if len(submission_part) > 0:\n",
    "        assert (submission_part.stop_frame > submission_part.start_frame).all(), \"stop <= start\"\n",
    "    \n",
    "    return submission_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54d2d97a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.436384Z",
     "iopub.status.busy": "2025-12-05T13:58:30.436212Z",
     "iopub.status.idle": "2025-12-05T13:58:30.444946Z",
     "shell.execute_reply": "2025-12-05T13:58:30.444432Z"
    },
    "papermill": {
     "duration": 0.014117,
     "end_time": "2025-12-05T13:58:30.445996",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.431879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_submission(submission, dataset, mode, traintest_directory=None):\n",
    "    \"\"\"\n",
    "    Làm sạch submission:\n",
    "    1. Bỏ các chuỗi start_frame >= stop_frame\n",
    "    2. Bỏ các chuỗi bị lặp (cùng agent-target)\n",
    "    3. Điền video trống với dummy predictions\n",
    "    \"\"\"\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{mode}_tracking\"\n",
    "        # traintest_directory = f\"D:/UET/ML/mouse_behavior/data/{mode}_tracking\"\n",
    "    \n",
    "    # Bỏ invalid frames\n",
    "    submission = submission[submission.start_frame < submission.stop_frame].copy()\n",
    "\n",
    "    # Bỏ rows có NaN\n",
    "    submission = submission.dropna(subset=[\"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"])\n",
    "    \n",
    "    # Bỏ chuỗi bị lặp\n",
    "    group_list = []\n",
    "    for _, group in submission.groupby([\"video_id\", \"agent_id\", \"target_id\"]):\n",
    "        group = group.sort_values(\"start_frame\")\n",
    "        mask = np.ones(len(group), dtype=bool)\n",
    "        last_stop_frame = 0\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            if row[\"start_frame\"] < last_stop_frame:\n",
    "                mask[i] = False\n",
    "            else:\n",
    "                last_stop_frame = row[\"stop_frame\"]\n",
    "        group_list.append(group[mask])\n",
    "    \n",
    "    submission = pd.concat(group_list)\n",
    "\n",
    "    if len(group_list) > 0:\n",
    "        submission = pd.concat(group_list, ignore_index=True)\n",
    "    else:\n",
    "        submission = pd.DataFrame(columns=[\"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"])\n",
    "    \n",
    "    # Điền video trống\n",
    "    s_list = []\n",
    "    for idx, row in dataset.iterrows():\n",
    "        lab_id = row[\"lab_id\"]\n",
    "        if lab_id.startswith('MABe22'):\n",
    "            continue\n",
    "        \n",
    "        video_id = row[\"video_id\"]\n",
    "        if (submission.video_id == video_id).any():\n",
    "            continue\n",
    "\n",
    "        if type(row.behaviors_labeled) != str:\n",
    "            continue\n",
    "        \n",
    "        print(f\"Video {video_id} has no predictions, filling...\")\n",
    "        \n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        try:\n",
    "            vid = pd.read_parquet(path)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        vid_behaviors = json.loads(row[\"behaviors_labeled\"])\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=[\"agent\", \"target\", \"action\"])\n",
    "        \n",
    "        start_frame = vid.video_frame.min()\n",
    "        stop_frame = vid.video_frame.max() + 1\n",
    "        \n",
    "        for (agent, target), actions in vid_behaviors.groupby([\"agent\", \"target\"]):\n",
    "            batch_length = int(np.ceil((stop_frame - start_frame) / len(actions)))\n",
    "            for i, (_, action_row) in enumerate(actions.iterrows()):\n",
    "                batch_start = start_frame + i * batch_length\n",
    "                batch_stop = min(batch_start + batch_length, stop_frame)\n",
    "                s_list.append((video_id, agent, target, action_row[\"action\"], batch_start, batch_stop))\n",
    "    \n",
    "    if len(s_list) > 0:\n",
    "        submission = pd.concat([\n",
    "            submission,\n",
    "            pd.DataFrame(s_list, columns=[\"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"])\n",
    "        ])\n",
    "    \n",
    "    submission = submission.reset_index(drop=True)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddace096",
   "metadata": {
    "papermill": {
     "duration": 0.003653,
     "end_time": "2025-12-05T13:58:30.453818",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.450165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pipeline train-and-submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c219c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.461692Z",
     "iopub.status.busy": "2025-12-05T13:58:30.461484Z",
     "iopub.status.idle": "2025-12-05T13:58:30.471280Z",
     "shell.execute_reply": "2025-12-05T13:58:30.470826Z"
    },
    "papermill": {
     "duration": 0.014906,
     "end_time": "2025-12-05T13:58:30.472214",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.457308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_models_and_submit_ensemble(body_parts_tracked_str, mode_train, X_all, y_all, meta_all, n_samples):\n",
    "    \"\"\"\n",
    "    Theo từng section/body_part_tracked, train binary classifiers cho từng action (trên bộ train) và predict (trên bộ test).\n",
    "    \"\"\"\n",
    "\n",
    "    models = []\n",
    "    \n",
    "    # Check GPU availability\n",
    "    gpu_available = torch.cuda.is_available()\n",
    "\n",
    "    X_all_np = X_all.to_numpy(np.float32, copy=False)\n",
    "    del X_all\n",
    "    gc.collect()\n",
    "\n",
    "    # NEW: tạo Ensemble model\n",
    "    # models = create_ensemble_models(mode=mode_train)\n",
    "\n",
    "    # Model 2: LightGBM\n",
    "    models.append(make_pipeline(\n",
    "        StratifiedSubsetClassifier(\n",
    "            lgb.LGBMClassifier(\n",
    "                n_estimators=300,\n",
    "                learning_rate=0.1,\n",
    "                num_leaves=63,\n",
    "                max_depth=8,\n",
    "                device_type=\"gpu\" if gpu_available else \"cpu\",\n",
    "                verbose=-1,\n",
    "                random_state=42\n",
    "            ), n_samples=int(n_samples), # new: train on all samples\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Model 3: XGBoost\n",
    "    models.append(make_pipeline(\n",
    "        StratifiedSubsetClassifier(\n",
    "            xgb.XGBClassifier(\n",
    "                n_estimators=400,\n",
    "                learning_rate=0.08,\n",
    "                max_depth=6,\n",
    "                tree_method=\"gpu_hist\" if gpu_available else \"hist\",\n",
    "                device=\"cuda\" if gpu_available else \"cpu\",\n",
    "                random_state=42\n",
    "            ), n_samples=int(n_samples) # new: train on all samples\n",
    "        )\n",
    "    ))\n",
    "\n",
    "    model_list = []\n",
    "    for action in y_all.columns:\n",
    "        y_raw = y_all[action].to_numpy()\n",
    "        mask = ~pd.isna(y_raw)\n",
    "        y_action = y_raw[mask].astype(int)\n",
    "        \n",
    "        if not (y_action == 0).all() and np.sum(y_action) >= 5:\n",
    "            trained = []\n",
    "            idx = np.flatnonzero(mask)\n",
    "            for m in models:\n",
    "                m_clone = clone(m)\n",
    "                m_clone.fit(X_all_np[idx], y_action)\n",
    "                trained.append(m_clone)\n",
    "            model_list.append((action, trained))\n",
    "\n",
    "    del X_all_np\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    # Build test data của body_part_tracked hiện tại\n",
    "    body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "    if len(body_parts_tracked) > 5:\n",
    "        body_parts_tracked = [b for b in body_parts_tracked if b not in CFG.drop_body_parts]\n",
    "    \n",
    "    test_subset = test_csv[test_csv.body_parts_tracked == body_parts_tracked_str]\n",
    "\n",
    "    # Predict single\n",
    "    generator = generate_mouse_data(\n",
    "        test_subset, \n",
    "        mode=\"test\", \n",
    "        generate_single=(mode_train == \"single\"), \n",
    "        generate_pair=(mode_train == \"pair\")\n",
    "    )\n",
    "\n",
    "    # Tạo fps_lookup cho test set\n",
    "    fps_lookup = (\n",
    "        test_subset[[\"video_id\", \"frames_per_second\"]]\n",
    "        .drop_duplicates(\"video_id\")\n",
    "        .set_index(\"video_id\")[\"frames_per_second\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    for mode_test, data_test, meta_test, actions_test in generator:\n",
    "        assert mode_test == mode_train\n",
    "        fps_i = _fps_from_meta(meta_test, fps_lookup, default_fps=30.0)\n",
    "\n",
    "        # Feature engineering\n",
    "        if mode_test == \"single\":\n",
    "            X_test = build_single_features(data_test, body_parts_tracked, fps_i).astype(np.float32)\n",
    "        else:\n",
    "            X_test = build_pair_features(data_test, body_parts_tracked, fps_i).astype(np.float32)\n",
    "\n",
    "        X_test_np = X_test.to_numpy(np.float32, copy=False)\n",
    "        del data_test\n",
    "        gc.collect()\n",
    "\n",
    "        # Predict\n",
    "        # preds = predict_actions_ensemble(X_test, model_list, actions_test)\n",
    "\n",
    "        pred = pd.DataFrame(index=meta_test.video_frame)\n",
    "        for action, trained in model_list:\n",
    "            if action in actions_test:\n",
    "                probs = [m.predict_proba(X_test_np)[:, 1] for m in trained]\n",
    "                pred[action] = np.average(probs, axis=0)\n",
    "\n",
    "        del X_test_np\n",
    "        gc.collect()\n",
    "\n",
    "        # if len(preds.columns) > 0:\n",
    "        if pred.shape[1] != 0:\n",
    "            sub_part = predict_multiclass_adaptive(pred, meta_test, CFG.action_thresholds)\n",
    "            submission_list.append(sub_part)\n",
    "\n",
    "    #     del X_test\n",
    "    #     gc.collect()\n",
    "\n",
    "    # return submission_parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d862f0",
   "metadata": {
    "papermill": {
     "duration": 0.003653,
     "end_time": "2025-12-05T13:58:30.479482",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.475829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1358a38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-05T13:58:30.487840Z",
     "iopub.status.busy": "2025-12-05T13:58:30.487610Z",
     "iopub.status.idle": "2025-12-05T14:45:54.661773Z",
     "shell.execute_reply": "2025-12-05T14:45:54.660930Z"
    },
    "papermill": {
     "duration": 2844.186449,
     "end_time": "2025-12-05T14:45:54.669637",
     "exception": false,
     "start_time": "2025-12-05T13:58:30.483188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAIN-AND-SUBMIT PIPELINE\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SECTION 0/8 (9 sections total): 9 bodyparts, 7 videos\n",
      "============================================================\n",
      "Processing 22 single mouse videos...\n",
      "Shape: 544859 frames × 59 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 60 pair mouse videos...\n",
      "Shape: 1524906 frames × 111 features\n",
      "\n",
      "============================================================\n",
      "SECTION 1/8 (9 sections total): 10 bodyparts, 21 videos\n",
      "============================================================\n",
      "Processing 32 single mouse videos...\n",
      "Shape: 478728 frames × 68 features\n",
      "Processing 41 pair mouse videos...\n",
      "Shape: 613716 frames × 130 features\n",
      "\n",
      "============================================================\n",
      "SECTION 2/8 (9 sections total): 9 bodyparts, 10 videos\n",
      "============================================================\n",
      "Processing 37 single mouse videos...\n",
      "Shape: 1941885 frames × 60 features\n",
      "Processing 106 pair mouse videos...\n",
      "Shape: 5607030 frames × 111 features\n",
      "\n",
      "============================================================\n",
      "SECTION 3/8 (9 sections total): 8 bodyparts, 42 videos\n",
      "============================================================\n",
      "Processing 76 pair mouse videos...\n",
      "Shape: 2210177 frames × 94 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (best_split_info.left_count) > (0) at /tmp/lightgbm/LightGBM/lightgbm-python/src/treelearner/serial_tree_learner.cpp, line 852 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SECTION 4/8 (9 sections total): 7 bodyparts, 74 videos\n",
      "============================================================\n",
      "Processing 76 pair mouse videos...\n",
      "Shape: 960574 frames × 79 features\n",
      "\n",
      "============================================================\n",
      "SECTION 5/8 (9 sections total): 5 bodyparts, 19 videos\n",
      "============================================================\n",
      "Processing 22 single mouse videos...\n",
      "Shape: 708496 frames × 33 features\n",
      "Processing 38 pair mouse videos...\n",
      "Shape: 10212910 frames × 55 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (best_split_info.left_count) > (0) at /tmp/lightgbm/LightGBM/lightgbm-python/src/treelearner/serial_tree_learner.cpp, line 852 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Exception*** Check failed: (best_split_info.left_count) > (0) at /tmp/lightgbm/LightGBM/lightgbm-python/src/treel\n",
      "\n",
      "============================================================\n",
      "SECTION 6/8 (9 sections total): 4 bodyparts, 17 videos\n",
      "============================================================\n",
      "Processing 34 single mouse videos...\n",
      "Shape: 899134 frames × 29 features\n",
      "Processing 34 pair mouse videos...\n",
      "Shape: 899134 frames × 46 features\n",
      "\n",
      "============================================================\n",
      "SECTION 7/8 (9 sections total): 7 bodyparts, 634 videos\n",
      "============================================================\n",
      "Processing 115 single mouse videos...\n",
      "Shape: 3020371 frames × 45 features\n",
      "Processing 677 pair mouse videos...\n",
      "Shape: 12259207 frames × 79 features\n",
      "\n",
      "============================================================\n",
      "SECTION 8/8 (9 sections total): 5 bodyparts, 24 videos\n",
      "============================================================\n",
      "Processing 9 single mouse videos...\n",
      "Shape: 329777 frames × 33 features\n",
      "Processing 46 pair mouse videos...\n",
      "Shape: 1700260 frames × 55 features\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SUBMISSION COMPLETE!\n",
      "============================================================\n",
      "Total events: 636\n",
      "Unique videos: 1\n",
      "Actions: {'rear': 318, 'avoid': 143, 'approach': 86, 'chase': 60, 'attack': 27, 'chaseattack': 2}\n",
      "Saved to: submission.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAIN-AND-SUBMIT PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# thresholds_all = {\"single\": {}, \"pair\": {}}\n",
    "submission_list = []\n",
    "\n",
    "for section in range(len(body_parts_list)):\n",
    "    # Lấy body_parts_tracked trong số 9 bộ của toàn dataset\n",
    "    body_parts_tracked_str = body_parts_list[section]\n",
    "\n",
    "    try:\n",
    "        body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "\n",
    "        if len(body_parts_tracked) > 5:\n",
    "            body_parts_tracked = [b for b in body_parts_tracked if b not in CFG.drop_body_parts]\n",
    "\n",
    "        # Lấy các rows/videos được thu với body_parts_tracked tương ứng\n",
    "        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n",
    "\n",
    "        if train_subset.empty:\n",
    "            print(\"\\nNo videos in this section, skipping...\")\n",
    "            continue\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"SECTION {section}/{len(body_parts_list)-1} (9 sections total): {len(body_parts_tracked)} bodyparts, {len(train_subset)} videos\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        fps_lookup = (\n",
    "            train_subset[[\"video_id\", \"frames_per_second\"]]\n",
    "            .drop_duplicates(\"video_id\")\n",
    "            .set_index(\"video_id\")[\"frames_per_second\"]\n",
    "            .to_dict()\n",
    "        )\n",
    "    \n",
    "        single_mouse = []\n",
    "        single_meta = []\n",
    "        single_y = []\n",
    "\n",
    "        pair_mouse = []\n",
    "        pair_meta = []\n",
    "        pair_y = []\n",
    "\n",
    "        # Accumulate generated data\n",
    "        for mode, data, meta, labels in generate_mouse_data(train_subset, mode=\"train\"):\n",
    "            video_id = meta[\"video_id\"].iloc[0]\n",
    "            fps = fps_lookup.get(video_id, 30.0)\n",
    "\n",
    "            if mode == \"single\":\n",
    "                single_mouse.append(data)\n",
    "                single_meta.append(meta)\n",
    "                single_y.append(labels)\n",
    "\n",
    "            else:\n",
    "                pair_mouse.append(data)\n",
    "                pair_meta.append(meta)\n",
    "                pair_y.append(labels)\n",
    "\n",
    "        # Single models\n",
    "        if len(single_mouse) > 0:\n",
    "            print(f\"Processing {len(single_mouse)} single mouse videos...\")\n",
    "            single_X = []\n",
    "\n",
    "            for data_i, meta_i, in zip(single_mouse, single_meta):\n",
    "                fps_i = _fps_from_meta(meta_i, fps_lookup, default_fps=30.0)\n",
    "\n",
    "                X_i = build_single_features(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                single_X.append(X_i)\n",
    "        \n",
    "            X_all = pd.concat(single_X, ignore_index=True)\n",
    "            y_all = pd.concat(single_y, ignore_index=True)\n",
    "            meta_all = pd.concat(single_meta, ignore_index=True)\n",
    "        \n",
    "            print(f\"Shape: {X_all.shape[0]} frames × {X_all.shape[1]} features\")\n",
    "        \n",
    "            # Train ENSEMBLE + ADAPTIVE THRESHOLDING và thực hiện predict\n",
    "            train_models_and_submit_ensemble(body_parts_tracked_str, \"single\", X_all, y_all, meta_all, 2_000_000)\n",
    "\n",
    "            del X_all, y_all, meta_all, single_X, single_mouse, single_meta, single_y\n",
    "            gc.collect()\n",
    "\n",
    "        # Train pair models\n",
    "        if len(pair_mouse) > 0:\n",
    "            print(f\"Processing {len(pair_mouse)} pair mouse videos...\")\n",
    "            pair_X = []\n",
    "            \n",
    "            for data_i, meta_i in zip(pair_mouse, pair_meta):\n",
    "                fps_i = _fps_from_meta(meta_i, fps_lookup, default_fps=30.0)\n",
    "\n",
    "                X_i = build_pair_features(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                pair_X.append(X_i)   \n",
    "\n",
    "            X_all = pd.concat(pair_X, ignore_index=True)\n",
    "            y_all = pd.concat(pair_y, ignore_index=True)\n",
    "            meta_all = pd.concat(pair_meta, ignore_index=True)  \n",
    "        \n",
    "            print(f\"Shape: {X_all.shape[0]} frames × {X_all.shape[1]} features\")\n",
    "        \n",
    "            # Train ENSEMBLE + ADAPTIVE THRESHOLDING + thực hiện predict\n",
    "            train_models_and_submit_ensemble(body_parts_tracked_str, \"pair\", X_all, y_all, meta_all, 900_000)\n",
    "\n",
    "            del X_all, y_all, meta_all, pair_X, pair_mouse, pair_y, pair_meta\n",
    "            gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"***Exception*** {str(e)[:100]}\")\n",
    "\n",
    "# Save thresholds\n",
    "# joblib.dump(thresholds_all, f\"{CFG.model_save_dir}/thresholds.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"Training complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "# Tạo final submission\n",
    "if len(submission_list) > 0:\n",
    "    submission = pd.concat(submission_list, ignore_index=True)\n",
    "else:\n",
    "    # Empty fallback\n",
    "    print(\"WARNING: No predictions generated!\")\n",
    "    submission = pd.DataFrame({\n",
    "        \"video_id\": [], \"agent_id\": [], \"target_id\": [],\n",
    "        \"action\": [], \"start_frame\": [], \"stop_frame\": []\n",
    "    })\n",
    "\n",
    "# Làm sạch submission\n",
    "submission = clean_submission(submission, test_csv, \"test\", CFG.test_tracking_path)\n",
    "    \n",
    "# Thêm row_id\n",
    "submission.insert(0, \"row_id\", range(len(submission)))\n",
    "    \n",
    "# Save\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "    \n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBMISSION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total events: {len(submission):,}\")\n",
    "print(f\"Unique videos: {submission.video_id.nunique()}\")\n",
    "print(f\"Actions: {submission.action.value_counts().to_dict()}\")\n",
    "print(f\"Saved to: submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 14715501,
     "datasetId": 8870798,
     "sourceId": 13944162,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2869.696846,
   "end_time": "2025-12-05T14:45:57.506710",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-05T13:58:07.809864",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
