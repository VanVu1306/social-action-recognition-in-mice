{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:26:24.433931Z",
     "iopub.status.busy": "2025-11-25T17:26:24.433651Z",
     "iopub.status.idle": "2025-11-25T17:26:24.438626Z",
     "shell.execute_reply": "2025-11-25T17:26:24.437920Z",
     "shell.execute_reply.started": "2025-11-25T17:26:24.433911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json, ast\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os, math\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:26:24.440063Z",
     "iopub.status.busy": "2025-11-25T17:26:24.439729Z",
     "iopub.status.idle": "2025-11-25T17:26:24.504115Z",
     "shell.execute_reply": "2025-11-25T17:26:24.503484Z",
     "shell.execute_reply.started": "2025-11-25T17:26:24.440045Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('D:/UET/ML/mouse_behavior/data/train.csv') \n",
    "test_csv = pd.read_csv('D:/UET/ML/mouse_behavior/data/test.csv')\n",
    "train_annotation_path = 'D:/UET/ML/mouse_behavior/data/train_annotation'\n",
    "train_tracking_path = 'D:/UET/ML/mouse_behavior/data/train_tracking'\n",
    "\n",
    "drop_body_parts =  [\n",
    "    'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', \n",
    "    'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', \n",
    "    'spine_1', 'spine_2', 'tail_middle_1', 'tail_middle_2', 'tail_midpoint'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:26:24.505591Z",
     "iopub.status.busy": "2025-11-25T17:26:24.505272Z",
     "iopub.status.idle": "2025-11-25T17:26:24.515582Z",
     "shell.execute_reply": "2025-11-25T17:26:24.514910Z",
     "shell.execute_reply.started": "2025-11-25T17:26:24.505566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mask_lab = train_csv['lab_id'].str.startswith('MABe22')\n",
    "mask_behavior = train_csv['behaviors_labeled'].isna() | (train_csv['behaviors_labeled'].str.strip() == \"\")\n",
    "mask_drop = mask_lab | mask_behavior\n",
    "\n",
    "train = train_csv[~mask_drop]\n",
    "body_parts_list = list(np.unique(train.body_parts_tracked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:26:24.516551Z",
     "iopub.status.busy": "2025-11-25T17:26:24.516339Z",
     "iopub.status.idle": "2025-11-25T17:26:24.527117Z",
     "shell.execute_reply": "2025-11-25T17:26:24.526461Z",
     "shell.execute_reply.started": "2025-11-25T17:26:24.516528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_tracking(traintest, lab_id, video_id, pix_per_cm, drop_body_parts=[]):\n",
    "    \"\"\"\n",
    "    Output: DataFrame pvid\n",
    "    Shape: (num_frames, (num_mice * num_bodyparts *2))\n",
    "    Mỗi hàm = 1 frame, mỗi cột = toạ độ x/y của 1 bodypart của 1 chuột\n",
    "    \"\"\"\n",
    "    video_path = f\"D:/UET/ML/mouse_behavior/data/{traintest}_tracking/{lab_id}/{video_id}.parquet\"\n",
    "    df = pd.read_parquet(video_path)\n",
    "\n",
    "    if len(np.unique(df.bodypart)) > 5:\n",
    "        df = df[~df.bodypart.isin(drop_body_parts)]\n",
    "\n",
    "    # Pivot: frame_idx = idx, columns = mouse_id và (x, y) của bodyparts\n",
    "    pvid = df.pivot(index=\"video_frame\", columns=[\"mouse_id\", \"bodypart\"], values=[\"x\", \"y\"])\n",
    "    pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T\n",
    "    pvid.columns = pvid.columns.set_names([\"mouse_id\", \"bodypart\", \"coord\"])\n",
    "\n",
    "    # Chuấn hoá pixel -> cm\n",
    "    pvid /= pix_per_cm\n",
    "\n",
    "    mouse_ids = pvid.columns.get_level_values(\"mouse_id\").unique()\n",
    "    pvid.attrs[\"mouse_ids\"] = mouse_ids\n",
    "    pvid.attrs[\"num_mice\"] = len(mouse_ids)\n",
    "    return pvid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:26:24.528797Z",
     "iopub.status.busy": "2025-11-25T17:26:24.528459Z",
     "iopub.status.idle": "2025-11-25T17:26:24.539796Z",
     "shell.execute_reply": "2025-11-25T17:26:24.539087Z",
     "shell.execute_reply.started": "2025-11-25T17:26:24.528757Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_single_mouse_dfs(pvid, annot=None):\n",
    "    \"\"\"\n",
    "    Trả về: list các DataFrame, mỗi DF ứng với 1 chuột\n",
    "    \"\"\"\n",
    "    single_dfs = []\n",
    "    mouse_ids = pvid.attrs[\"mouse_ids\"]\n",
    "\n",
    "    # Annotation self-oriented\n",
    "    if annot is not None:\n",
    "        annot_self = annot[annot.agent_id == annot.target_id]\n",
    "    else:\n",
    "        annot_self = None\n",
    "\n",
    "    for mouse_id in mouse_ids:\n",
    "        # Meta info\n",
    "        meta = pd.DataFrame({\n",
    "            \"video_frame\": pvid.index,\n",
    "            \"agent_id\": mouse_id,\n",
    "            \"target_id\": mouse_id\n",
    "        }, index=pvid.index)\n",
    "        \n",
    "        # Features tracking của chuột\n",
    "        mouse_features = pvid[mouse_id].copy()\n",
    "\n",
    "        # Build labels\n",
    "        if annot_self is not None:\n",
    "            subset = annot_self[annot_self.agent_id == mouse_id]\n",
    "\n",
    "            actions = subset[\"action\"].unique()\n",
    "            labels = pd.DataFrame(0, index=pvid.index, columns=actions)\n",
    "\n",
    "            for _, row in subset.iterrows():\n",
    "                labels.loc[row.start_frame:row.stop_frame, row.action] = 1\n",
    "        else:\n",
    "            labels = None\n",
    "\n",
    "        # Gom vào 1 dataframe\n",
    "        if labels is not None:\n",
    "            df_mouse = pd.concat([mouse_features, meta, labels], axis=1)\n",
    "        else:\n",
    "            df_mouse = pd.concat([mouse_features, meta], axis=1)\n",
    "\n",
    "        # Thêm vào list\n",
    "        single_dfs.append(df_mouse)\n",
    "\n",
    "    return single_dfs\n",
    "\n",
    "def create_mouse_pair_dfs(pvid, annot=None):\n",
    "    \"\"\"\n",
    "    Trả về: list các DataFrame, mỗi DF ứng với 1 cặp agent-target\n",
    "    \"\"\"\n",
    "    pair_dfs = []\n",
    "\n",
    "    # Annotation social-oriented\n",
    "    if annot is not None:\n",
    "        annot_pair = annot[annot.agent_id != annot.target_id]\n",
    "    else:\n",
    "        annot_pair = None\n",
    "\n",
    "    # Get unique mouse IDs\n",
    "    mouse_ids = np.unique(pvid.columns.get_level_values(\"mouse_id\"))\n",
    "\n",
    "    for agent, target in itertools.permutations(mouse_ids, 2):\n",
    "        # Meta info\n",
    "        meta = pd.DataFrame({\n",
    "            \"video_frame\": pvid.index,\n",
    "            \"agent_id\": agent,\n",
    "            \"target_id\": target\n",
    "        }, index=pvid.index)\n",
    "\n",
    "        # Features tracking của agent-target\n",
    "        pair_features = pvid.loc[:, pvid.columns.get_level_values(\"mouse_id\").isin([agent, target])]\n",
    "\n",
    "        mapping = {agent: \"A\", target: \"B\"}\n",
    "        pair_features.columns = pd.MultiIndex.from_tuples(\n",
    "            [(mapping[m], bodypart, coord) for m, bodypart, coord in pair_features.columns]\n",
    "        )\n",
    "\n",
    "        # Build labels\n",
    "        if annot_pair is not None:\n",
    "            subset = annot_pair[(annot_pair.agent_id==agent) & (annot_pair.target_id==target)]\n",
    "            actions = subset[\"action\"].unique()\n",
    "            labels = pd.DataFrame(0, index=pvid.index, columns=actions)\n",
    "            for _, row in subset.iterrows():\n",
    "                labels.loc[row.start_frame:row.stop_frame, row.action] = 1\n",
    "            df_mouses = pd.concat([pair_features, meta, labels], axis=1)\n",
    "        else:\n",
    "            df_mouses = pd.concat([pair_features, meta], axis=1)\n",
    "\n",
    "        pair_dfs.append(df_mouses)\n",
    "\n",
    "    return pair_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:26:24.597895Z",
     "iopub.status.busy": "2025-11-25T17:26:24.597502Z",
     "iopub.status.idle": "2025-11-25T17:26:24.610363Z",
     "shell.execute_reply": "2025-11-25T17:26:24.609687Z",
     "shell.execute_reply.started": "2025-11-25T17:26:24.597879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_centers(df):\n",
    "    \"\"\"\n",
    "    Ensure that 'body_center' exists for all mice or bodyparts combinations.\n",
    "    Handles both 2-level (bodypart, coord) and 3-level (mouse_id, bodypart, coord) columns.\n",
    "    \n",
    "    Fallback logic:\n",
    "    1. If nose and tail_base exist → midpoint(nose, tail_base)\n",
    "    2. Else if head and tail_base exist → midpoint(head, tail_base)\n",
    "    3. Else if only tail_base exists → use tail_base\n",
    "    4. Else → cannot compute body_center\n",
    "    \"\"\"\n",
    "    cols = df.columns\n",
    "\n",
    "    # --- 2-level columns (bodypart, coord) ---\n",
    "    if cols.nlevels == 2:\n",
    "        if (\"body_center\", \"x\") not in df.columns or (\"body_center\", \"y\") not in df.columns:\n",
    "            if (\"nose\", \"x\") in df.columns and (\"tail_base\", \"x\") in df.columns:\n",
    "                df[(\"body_center\", \"x\")] = (df[(\"nose\", \"x\")] + df[(\"tail_base\", \"x\")]) / 2\n",
    "                df[(\"body_center\", \"y\")] = (df[(\"nose\", \"y\")] + df[(\"tail_base\", \"y\")]) / 2\n",
    "            elif (\"head\", \"x\") in df.columns and (\"tail_base\", \"x\") in df.columns:\n",
    "                df[(\"body_center\", \"x\")] = (df[(\"head\", \"x\")] + df[(\"tail_base\", \"x\")]) / 2\n",
    "                df[(\"body_center\", \"y\")] = (df[(\"head\", \"y\")] + df[(\"tail_base\", \"y\")]) / 2\n",
    "            elif (\"tail_base\", \"x\") in df.columns:\n",
    "                df[(\"body_center\", \"x\")] = df[(\"tail_base\", \"x\")]\n",
    "                df[(\"body_center\", \"y\")] = df[(\"tail_base\", \"y\")]\n",
    "            else:\n",
    "                # no valid bodyparts → fill NaN\n",
    "                df[(\"body_center\", \"x\")] = np.nan\n",
    "                df[(\"body_center\", \"y\")] = np.nan\n",
    "\n",
    "    # --- 3-level columns (mouse_id, bodypart, coord) ---\n",
    "    elif cols.nlevels == 3:\n",
    "        mice = sorted(list(set(c[0] for c in cols)))\n",
    "\n",
    "        for m in mice:\n",
    "            has_body_center = ((m, \"body_center\", \"x\") in cols) and ((m, \"body_center\", \"y\") in cols)\n",
    "            if not has_body_center:\n",
    "                if ((m, \"nose\", \"x\") in cols) and ((m, \"tail_base\", \"x\") in cols):\n",
    "                    df[(m, \"body_center\", \"x\")] = (df[(m, \"nose\", \"x\")] + df[(m, \"tail_base\", \"x\")]) / 2\n",
    "                    df[(m, \"body_center\", \"y\")] = (df[(m, \"nose\", \"y\")] + df[(m, \"tail_base\", \"y\")]) / 2\n",
    "                elif ((m, \"head\", \"x\") in cols) and ((m, \"tail_base\", \"x\") in cols):\n",
    "                    df[(m, \"body_center\", \"x\")] = (df[(m, \"head\", \"x\")] + df[(m, \"tail_base\", \"x\")]) / 2\n",
    "                    df[(m, \"body_center\", \"y\")] = (df[(m, \"head\", \"y\")] + df[(m, \"tail_base\", \"y\")]) / 2\n",
    "                elif ((m, \"tail_base\", \"x\") in cols):\n",
    "                    df[(m, \"body_center\", \"x\")] = df[(m, \"tail_base\", \"x\")]\n",
    "                    df[(m, \"body_center\", \"y\")] = df[(m, \"tail_base\", \"y\")]\n",
    "                else:\n",
    "                    df[(m, \"body_center\", \"x\")] = np.nan\n",
    "                    df[(m, \"body_center\", \"y\")] = np.nan\n",
    "    return df\n",
    "\n",
    "def calculate_speed_lag(df, part, fps, lag=10, mouse=None):\n",
    "    cols = df.columns\n",
    "    if mouse is not None:\n",
    "        x = df[(mouse, part, \"x\")]\n",
    "        y = df[(mouse, part, \"y\")]\n",
    "    else:\n",
    "        x = df[(part, \"x\")]\n",
    "        y = df[(part, \"y\")]\n",
    "\n",
    "    if x.isna().all() or y.isna().all():\n",
    "        # all missing → return zeros\n",
    "        return pd.Series(0, index=df.index)\n",
    "\n",
    "    dx = x.diff(lag)\n",
    "    dy = y.diff(lag)\n",
    "    speed = np.sqrt(dx**2 + dy**2) * fps\n",
    "    return speed.fillna(0)\n",
    "\n",
    "# Tính các thống kê của 1 đại lượng theo nhiều cửa sổ thời gian\n",
    "def calculate_window_stats(df, metric, name, fps, scales=[20, 40, 60, 80]):\n",
    "    \"\"\"\n",
    "    Thêm rolling statistics cho bất kỳ series nào.\n",
    "    \n",
    "    metric : pd.Series (ví dụ speed, distance, curvature...)\n",
    "    fps    : frames_per_second\n",
    "    scales : list window sizes quy đổi theo 30fps → mặc định [20,40,60,80]\n",
    "    \"\"\"\n",
    "    res = pd.DataFrame(index=df.index)\n",
    "    for scale in scales:\n",
    "        ws = max(1, int(round(scale * float(fps) / 30)))\n",
    "        roll = metric.rolling(ws, min_periods=max(1, ws//4))\n",
    "\n",
    "        res[f\"{name}_mean_{scale}\"] = roll.mean()\n",
    "        res[f\"{name}_std_{scale}\"]  = roll.std()\n",
    "        res[f\"{name}_min_{scale}\"]  = roll.min()\n",
    "        res[f\"{name}_max_{scale}\"]  = roll.max()\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:26:24.611417Z",
     "iopub.status.busy": "2025-11-25T17:26:24.611228Z",
     "iopub.status.idle": "2025-11-25T17:26:24.630005Z",
     "shell.execute_reply": "2025-11-25T17:26:24.629314Z",
     "shell.execute_reply.started": "2025-11-25T17:26:24.611397Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_single_features(single_mouse_df, meta_fps):\n",
    "    df_features = pd.DataFrame(index=single_mouse_df.index)\n",
    "    \n",
    "    # Get actual bodypart columns\n",
    "    bodyparts = [col[0] for col in single_mouse_df.columns if isinstance(col, tuple)]\n",
    "    \n",
    "    single_mouse_df = calculate_centers(single_mouse_df)\n",
    "    \n",
    "    # === Shape and Position Features ===\n",
    "    # Euclidean distances between bodyparts\n",
    "    distances = pd.DataFrame({\n",
    "        f\"{p1}+{p2}\": np.sqrt(\n",
    "            (single_mouse_df[(p1, \"x\")] - single_mouse_df[(p2, \"x\")])**2 + \n",
    "            (single_mouse_df[(p1, \"y\")] - single_mouse_df[(p2, \"y\")])**2\n",
    "        )\n",
    "        for p1, p2 in itertools.combinations(bodyparts, 2)\n",
    "    }, index=single_mouse_df.index)\n",
    "    \n",
    "    df_features = pd.concat([df_features, distances], axis=1)\n",
    "    \n",
    "    # Elongation (only if required bodyparts exist)\n",
    "    if \"nose\" in bodyparts and \"tail_base\" in bodyparts and \"ear_left\" in bodyparts and \"ear_right\" in bodyparts:\n",
    "        df_features[\"elong\"] = distances[\"nose+tail_base\"] / distances[\"ear_left+ear_right\"]\n",
    "    \n",
    "    # Body angle (only if nose, tail_base, body_center exist)\n",
    "    if all(bp in bodyparts for bp in [\"nose\", \"tail_base\", \"body_center\"]):\n",
    "        v1_x = single_mouse_df[(\"nose\",\"x\")] - single_mouse_df[(\"body_center\",\"x\")]\n",
    "        v1_y = single_mouse_df[(\"nose\",\"y\")] - single_mouse_df[(\"body_center\",\"y\")]\n",
    "        v2_x = single_mouse_df[(\"tail_base\",\"x\")] - single_mouse_df[(\"body_center\",\"x\")]\n",
    "        v2_y = single_mouse_df[(\"tail_base\",\"y\")] - single_mouse_df[(\"body_center\",\"y\")]\n",
    "        df_features[\"body_angle\"] = (v1_x*v2_x + v1_y*v2_y) / (np.sqrt(v1_x**2+v1_y**2) * np.sqrt(v2_x**2+v2_y**2) + 1e-6)\n",
    "    \n",
    "    # === Movement Features ===\n",
    "    if \"body_center\" in bodyparts:\n",
    "        df_features[\"speed\"] = np.sqrt(\n",
    "            single_mouse_df[(\"body_center\", \"x\")].diff()**2 +\n",
    "            single_mouse_df[(\"body_center\", \"y\")].diff()**2\n",
    "        )\n",
    "        df_features[\"accelerate\"] = df_features[\"speed\"].diff()\n",
    "    \n",
    "    # Speed lag features for available bodyparts\n",
    "    for p in [\"body_center\", \"ear_left\", \"ear_right\"]:\n",
    "        if p in bodyparts:\n",
    "            df_features[f\"speed_{p}_lag_10\"] = calculate_speed_lag(single_mouse_df, p, fps=meta_fps)\n",
    "    \n",
    "    # Rolling stats for available bodyparts\n",
    "    for part in bodyparts:\n",
    "        speed = np.sqrt(single_mouse_df[(part, \"x\")].diff()**2 + single_mouse_df[(part, \"y\")].diff()**2) * float(meta_fps)\n",
    "        res = calculate_window_stats(single_mouse_df, speed, f\"speed_{part}\", fps=meta_fps)\n",
    "        df_features = pd.concat([df_features, res], axis=1)\n",
    "    \n",
    "    # Curvature for available bodyparts\n",
    "    for p in [\"body_center\", \"ear_left\", \"ear_right\"]:\n",
    "        if p in bodyparts:\n",
    "            lag = max(1, int(round(10 * float(meta_fps) / 30)))\n",
    "            shifted_x = single_mouse_df[(p,\"x\")].shift(lag)\n",
    "            shifted_y = single_mouse_df[(p,\"y\")].shift(lag)\n",
    "            df_features[f\"curvature_{p}_lag_{lag}\"] = np.sqrt((shifted_x - single_mouse_df[(p,\"x\")])**2 + \n",
    "                                                              (shifted_y - single_mouse_df[(p,\"y\")])**2)\n",
    "\n",
    "    df_features = df_features.T.drop_duplicates().T\n",
    "    \n",
    "    return df_features.fillna(0)\n",
    "\n",
    "\n",
    "def build_pair_features(mouse_pair_df, meta_fps):\n",
    "    df_features = pd.DataFrame(index=mouse_pair_df.index)\n",
    "    \n",
    "    # Get bodyparts for both mice\n",
    "    bodyparts_A = [c[1] for c in mouse_pair_df.columns if isinstance(c, tuple) and c[0] == \"A\"]\n",
    "    bodyparts_B = [c[1] for c in mouse_pair_df.columns if isinstance(c, tuple) and c[0] == \"B\"]\n",
    "    \n",
    "    mouse_pair_df = calculate_centers(mouse_pair_df)\n",
    "    \n",
    "    # Pairwise distances\n",
    "    distances = pd.DataFrame({\n",
    "        f\"A_{p1}+B_{p2}\": np.sqrt(\n",
    "            (mouse_pair_df[(\"A\", p1, \"x\")] - mouse_pair_df[(\"B\", p2, \"x\")])**2 +\n",
    "            (mouse_pair_df[(\"A\", p1, \"y\")] - mouse_pair_df[(\"B\", p2, \"y\")])**2\n",
    "        )\n",
    "        for p1, p2 in itertools.product(bodyparts_A, bodyparts_B)\n",
    "    }, index=mouse_pair_df.index)\n",
    "    \n",
    "    df_features = pd.concat([df_features, distances], axis=1)\n",
    "    \n",
    "    # Relative orientation (only if nose and tail_base exist for both)\n",
    "    if all(bp in bodyparts_A for bp in [\"nose\",\"tail_base\"]) and all(bp in bodyparts_B for bp in [\"nose\",\"tail_base\"]):\n",
    "        vec_A_x = mouse_pair_df[(\"A\", \"nose\", \"x\")] - mouse_pair_df[(\"A\", \"tail_base\", \"x\")]\n",
    "        vec_A_y = mouse_pair_df[(\"A\", \"nose\", \"y\")] - mouse_pair_df[(\"A\", \"tail_base\", \"y\")]\n",
    "        vec_B_x = mouse_pair_df[(\"B\", \"nose\", \"x\")] - mouse_pair_df[(\"B\", \"tail_base\", \"x\")]\n",
    "        vec_B_y = mouse_pair_df[(\"B\", \"nose\", \"y\")] - mouse_pair_df[(\"B\", \"tail_base\", \"y\")]\n",
    "        df_features[\"relative_orientation\"] = (vec_A_x*vec_B_x + vec_A_y*vec_B_y) / (\n",
    "            np.sqrt(vec_A_x**2 + vec_A_y**2) * np.sqrt(vec_B_x**2 + vec_B_y**2) + 1e-6\n",
    "        )\n",
    "    else: \n",
    "        vec_A_x = mouse_pair_df[(\"A\", \"head\", \"x\")] - mouse_pair_df[(\"A\", \"tail_base\", \"x\")]\n",
    "        vec_A_y = mouse_pair_df[(\"A\", \"head\", \"y\")] - mouse_pair_df[(\"A\", \"tail_base\", \"y\")]\n",
    "        vec_B_x = mouse_pair_df[(\"B\", \"head\", \"x\")] - mouse_pair_df[(\"B\", \"tail_base\", \"x\")]\n",
    "        vec_B_y = mouse_pair_df[(\"B\", \"head\", \"y\")] - mouse_pair_df[(\"B\", \"tail_base\", \"y\")]\n",
    "        df_features[\"relative_orientation\"] = (vec_A_x*vec_B_x + vec_A_y*vec_B_y) / (\n",
    "            np.sqrt(vec_A_x**2 + vec_A_y**2) * np.sqrt(vec_B_x**2 + vec_B_y**2) + 1e-6\n",
    "        )\n",
    "    \n",
    "    # Center distance and approach\n",
    "    if \"body_center\" in bodyparts_A and \"body_center\" in bodyparts_B:\n",
    "        dist_center = np.sqrt(\n",
    "            (mouse_pair_df[(\"A\", \"body_center\", \"x\")] - mouse_pair_df[(\"B\", \"body_center\", \"x\")])**2 +\n",
    "            (mouse_pair_df[(\"A\", \"body_center\", \"y\")] - mouse_pair_df[(\"B\", \"body_center\", \"y\")])**2\n",
    "        )\n",
    "        approach = dist_center.diff().fillna(0)\n",
    "        df_features[\"approach_A\"] = approach\n",
    "        df_features[\"approach_B\"] = approach\n",
    "        \n",
    "        # Relative distance stats\n",
    "        res = calculate_window_stats(mouse_pair_df, dist_center**2, \"center_distance\", fps=meta_fps)\n",
    "        df_features = pd.concat([df_features, res], axis=1)\n",
    "        \n",
    "        # Relative speed\n",
    "        speed_A = calculate_speed_lag(mouse_pair_df, \"body_center\", meta_fps, mouse=\"A\")\n",
    "        speed_B = calculate_speed_lag(mouse_pair_df, \"body_center\", meta_fps, mouse=\"B\")\n",
    "        df_features[\"speed_A_lag_10\"] = speed_A\n",
    "        df_features[\"speed_B_lag_10\"] = speed_B\n",
    "        df_features[\"relative_speed_A_B_lag_10\"] = (speed_A - speed_B).abs()\n",
    "\n",
    "    df_features = df_features.T.drop_duplicates().T\n",
    "    \n",
    "    return df_features.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:26:24.631172Z",
     "iopub.status.busy": "2025-11-25T17:26:24.630961Z",
     "iopub.status.idle": "2025-11-25T17:26:24.645519Z",
     "shell.execute_reply": "2025-11-25T17:26:24.644778Z",
     "shell.execute_reply.started": "2025-11-25T17:26:24.631150Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_mouse_data(dataset, traintest, drop_body_parts=[]):\n",
    "    \"\"\"\n",
    "    Tạo DataFrames cho mỗi chuột và mỗi cặp chuột trong 1 video\n",
    "    Trả về danh sách DataFrames\n",
    "    \"\"\"\n",
    "    all_single = []\n",
    "    all_pair = []\n",
    "\n",
    "    for _, row in dataset.iterrows():\n",
    "        # Meta info\n",
    "        lab_id = row.lab_id\n",
    "        video_id = row.video_id\n",
    "        pix_per_cm = row.pix_per_cm_approx\n",
    "        meta_fps = row.frames_per_second\n",
    "\n",
    "        if lab_id.startswith('MABe22') or type(row.behaviors_labeled) != str: \n",
    "            continue\n",
    "\n",
    "        # Đọc tracking\n",
    "        pvid = read_tracking(traintest, lab_id, video_id, pix_per_cm, drop_body_parts=drop_body_parts)\n",
    "        \n",
    "        # Đọc annotation\n",
    "        annot = None\n",
    "        if traintest == \"train\":\n",
    "            annot_path = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_annotation/{lab_id}/{video_id}.parquet\"\n",
    "\n",
    "            if not os.path.exists(annot_path):\n",
    "                print(f\"Skipping video {video_id} (annotation not found)\")\n",
    "                continue\n",
    "\n",
    "            annot = pd.read_parquet(annot_path)\n",
    "            \n",
    "        # Tạo DataFrame cho từng chuột\n",
    "        sdfs = create_single_mouse_dfs(pvid, annot)\n",
    "\n",
    "        for df_single in sdfs:\n",
    "            df_features = build_single_features(df_single, meta_fps)\n",
    "            df_meta = df_single[[\"video_frame\",\"agent_id\",\"target_id\"]]\n",
    "\n",
    "            if annot is not None: \n",
    "                df_labels = df_single[[c for c in df_single.columns \n",
    "                        if (not isinstance(c, tuple)) and (c not in df_meta.columns)]]\n",
    "                \n",
    "            else:\n",
    "                df_labels = pd.DataFrame(index=df_single.index)\n",
    "\n",
    "            all_single.append([df_meta, df_features, df_labels])\n",
    "\n",
    "        # Nếu có nhiều hơn 1 chuột, tạo DataFrame cho từng cặp chuột\n",
    "        if pvid.attrs[\"num_mice\"] > 1:\n",
    "            pdfs = create_mouse_pair_dfs(pvid, annot)\n",
    "            for df_pair in pdfs:\n",
    "                df_features = build_pair_features(df_pair, meta_fps)\n",
    "                df_meta = df_pair[[\"video_frame\",\"agent_id\",\"target_id\"]]\n",
    "                \n",
    "                if annot is not None:\n",
    "                    df_labels = df_pair[[c for c in df_pair.columns \n",
    "                           if (not isinstance(c, tuple)) and (c not in df_meta.columns)]]\n",
    "                else:\n",
    "                    df_labels = pd.DataFrame(index=df_pair.index)\n",
    "\n",
    "                all_pair.append([df_meta, df_features, df_labels])\n",
    "\n",
    "    return all_single.astype(np.float32), all_pair.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T17:26:24.646587Z",
     "iopub.status.busy": "2025-11-25T17:26:24.646266Z",
     "iopub.status.idle": "2025-11-25T17:26:24.659246Z",
     "shell.execute_reply": "2025-11-25T17:26:24.658487Z",
     "shell.execute_reply.started": "2025-11-25T17:26:24.646564Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_binary_classifiers(data_list, mode, model, section, n_splits=5):\n",
    "    \"\"\"\n",
    "    data_list: list of (df_meta, df_feat, df_lab) for each video (one section)\n",
    "    mode: \"single\" or \"pair\"\n",
    "    model: scikit-learn estimator (cloneable)\n",
    "    section: int used for saving directory\n",
    "    n_splits: GroupKFold splits (minimum groups required)\n",
    "\n",
    "    Returns:\n",
    "        f1_list: list of (section, action, best_f1)\n",
    "        thresholds: dict action -> best_threshold\n",
    "    \"\"\"\n",
    "\n",
    "    save_dir = f\"models/{section}/{mode}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    thresholds = {}\n",
    "    f1_list = []\n",
    "\n",
    "    # Gather all actions in this section\n",
    "    all_actions = set()\n",
    "    for _, _, df_lab in data_list:\n",
    "        all_actions.update(df_lab.columns)\n",
    "    all_actions = sorted(all_actions)\n",
    "\n",
    "    if len(all_actions) == 0:\n",
    "        print(f\"[Section {section} | {mode}] No actions found, skipping.\")\n",
    "        return f1_list, thresholds\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    #   TRAIN SEPARATE MODEL FOR EACH ACTION\n",
    "    # ---------------------------------------------------------\n",
    "    for action in all_actions:\n",
    "        print(f\"\\n[Section {section} | {mode}] Preparing data for action: {action}\")\n",
    "\n",
    "        feat_dfs = []      \n",
    "        label_arrays = []  \n",
    "        group_labels = []  \n",
    "        video_idx = 0\n",
    "\n",
    "        # -------- Collect per-video data --------\n",
    "        for vid_idx, (df_meta, df_feat, df_lab) in enumerate(data_list):\n",
    "\n",
    "            if action not in df_lab.columns:\n",
    "                continue\n",
    "\n",
    "            y = df_lab[action].values.astype(np.int8)\n",
    "            if y.sum() == 0:\n",
    "                continue\n",
    "\n",
    "            groups = np.full(len(y), video_idx, dtype=np.int32)\n",
    "\n",
    "            # Ensure df_feat is DataFrame\n",
    "            if not isinstance(df_feat, pd.DataFrame):\n",
    "                df_feat = pd.DataFrame(df_feat)\n",
    "\n",
    "            feat_dfs.append(df_feat)\n",
    "            label_arrays.append(y)\n",
    "            group_labels.append(groups)\n",
    "\n",
    "            video_idx += 1\n",
    "\n",
    "        n_videos_for_action = len(feat_dfs)\n",
    "        if n_videos_for_action == 0:\n",
    "            print(f\"[Section {section} | {mode}] Action '{action}' has no positive videos — skipping.\")\n",
    "            continue\n",
    "\n",
    "        if n_videos_for_action < n_splits:\n",
    "            print(f\"[Section {section} | {mode}] Action '{action}' only appears in {n_videos_for_action} videos (< {n_splits}), skipping.\")\n",
    "            continue\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        #   ALIGN COLUMNS (union of all columns) – duplicates removed already upstream\n",
    "        # ---------------------------------------------------------\n",
    "        all_cols = sorted({c for df in feat_dfs for c in df.columns})\n",
    "\n",
    "        for i in range(len(feat_dfs)):\n",
    "            feat_dfs[i] = feat_dfs[i].reindex(columns=all_cols).fillna(0).astype(np.float32)\n",
    "\n",
    "        # -------- Stack all videos --------\n",
    "        X_all_df = pd.concat(feat_dfs, axis=0, ignore_index=True)\n",
    "        y_all = np.concatenate(label_arrays).astype(np.int8)\n",
    "        groups_all = np.concatenate(group_labels).astype(np.int32)\n",
    "\n",
    "        X_all = X_all_df.values \n",
    "        del X_all_df, feat_dfs, label_arrays, group_labels\n",
    "        gc.collect()\n",
    "\n",
    "        N = len(y_all)\n",
    "        if X_all.shape[0] != N:\n",
    "            raise RuntimeError(\"X_all and y_all size mismatch.\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        #   OUT-OF-FOLD PREDICTIONS (GroupKFold)\n",
    "        # ---------------------------------------------------------\n",
    "        oof_preds = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "        unique_groups = np.unique(groups_all)\n",
    "        gkf_splits = min(n_splits, len(unique_groups))\n",
    "        gkf = GroupKFold(n_splits=gkf_splits)\n",
    "\n",
    "        idx = np.arange(N)\n",
    "        for train_idx, val_idx in gkf.split(idx, y_all, groups_all):\n",
    "            clf = clone(model)\n",
    "            clf.fit(X_all[train_idx], y_all[train_idx])\n",
    "            oof_preds[val_idx] = clf.predict_proba(X_all[val_idx])[:, 1]\n",
    "            del clf\n",
    "            gc.collect()\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        #   THRESHOLD TUNING\n",
    "        # ---------------------------------------------------------\n",
    "        best_f1, best_thresh = 0.0, 0.5\n",
    "        for t in np.linspace(0.1, 0.9, 17):\n",
    "            preds_bin = (oof_preds >= t).astype(int)\n",
    "            f1 = f1_score(y_all, preds_bin, zero_division=0)\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_thresh = f1, float(t)\n",
    "\n",
    "        thresholds[action] = best_thresh\n",
    "        f1_list.append((section, action, best_f1))\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        #   FINAL MODEL TRAINING ON ALL DATA\n",
    "        # ---------------------------------------------------------\n",
    "        final_clf = clone(model)\n",
    "        final_clf.fit(X_all, y_all)\n",
    "\n",
    "        joblib.dump(final_clf, f\"{save_dir}/{action}_model.pkl\")\n",
    "        joblib.dump(best_thresh, f\"{save_dir}/{action}_threshold.pkl\")\n",
    "\n",
    "        print(f\"[Section {section} | {mode}] Action '{action}': {n_videos_for_action} videos, {N} samples, F1={best_f1:.4f}, thr={best_thresh:.3f}\")\n",
    "\n",
    "        del final_clf, X_all, y_all, groups_all, oof_preds\n",
    "        gc.collect()\n",
    "\n",
    "    return f1_list, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-25T19:27:43.094Z",
     "iopub.execute_input": "2025-11-25T17:26:24.661379Z",
     "iopub.status.busy": "2025-11-25T17:26:24.661147Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "thresholds = {\"single\": {}, \"pair\": {}}\n",
    "f1_list = []\n",
    "submission_list = []\n",
    "\n",
    "# Train model\n",
    "for section in range(1, len(body_parts_list)):\n",
    "    # Lấy body_parts_tracked trong số 9 bộ của toàn dataset\n",
    "    body_parts_tracked = body_parts_list[section]\n",
    "\n",
    "    # Lấy các rows/videos được thu với body_parts_tracked tương ứng\n",
    "    train_subset = train[train.body_parts_tracked == body_parts_tracked]\n",
    "\n",
    "    if train_subset.empty:\n",
    "        print(\"\\nNo videos in this section, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Data từng chuột + Data cặp chuột của toàn bộ videos trong subset\n",
    "    single_data, pair_data = generate_mouse_data(train_subset, \"train\", drop_body_parts)\n",
    "\n",
    "    # Tạo model\n",
    "    trainer = xgb.XGBClassifier(n_estimators=150, learning_rate=0.08, max_depth=4,\n",
    "                            subsample=0.7, colsample_bytree=0.7, random_state=42)\n",
    "\n",
    "    # Train XGBoost\n",
    "    if len(single_data) > 0:\n",
    "        single_f1_list, single_thresholds = train_binary_classifiers(single_data, \"single\", trainer, section, n_splits=3)\n",
    "\n",
    "    if len(pair_data) > 0:\n",
    "        pair_f1_list, pair_thresholds = train_binary_classifiers(pair_data, \"pair\", trainer, section, n_splits=3)\n",
    "\n",
    "    f1_list.extend(single_f1_list)\n",
    "    f1_list.extend(pair_f1_list)\n",
    "    thresholds[\"single\"][section] = single_thresholds\n",
    "    thresholds[\"pair\"][section] = pair_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-25T19:27:43.095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def detect_action_segments(frames, preds, min_length=1):\n",
    "    \"\"\"\n",
    "    frames: np.array các frame index (ví dụ: [0,1,2,3,...])\n",
    "    preds: np.array nhị phân 0/1 dự đoán theo từng frame\n",
    "    min_length: độ dài tối thiểu của 1 segment (theo số frame)\n",
    "    \n",
    "    return: list[(start_frame, stop_frame)]\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    in_segment = False\n",
    "    start_frame = None\n",
    "\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == 1 and not in_segment:\n",
    "            # bắt đầu 1 đoạn mới\n",
    "            in_segment = True\n",
    "            start_frame = frames[i]\n",
    "\n",
    "        elif preds[i] == 0 and in_segment:\n",
    "            # kết thúc đoạn\n",
    "            end_frame = frames[i - 1]\n",
    "            if end_frame - start_frame + 1 >= min_length:\n",
    "                segments.append((start_frame, end_frame))\n",
    "            in_segment = False\n",
    "\n",
    "    # Nếu kết thúc file mà vẫn đang trong segment\n",
    "    if in_segment:\n",
    "        end_frame = frames[-1]\n",
    "        if end_frame - start_frame + 1 >= min_length:\n",
    "            segments.append((start_frame, end_frame))\n",
    "\n",
    "    return segments\n",
    "\n",
    "def create_submission(test_results, video_id): \n",
    "    \"\"\" \n",
    "    test_results: predictions của toàn bộ test videos \n",
    "    video_id: ID của video test \n",
    "    \"\"\" \n",
    "    rows = [] \n",
    "    for (_, df_meta, df_preds) in test_results:\n",
    "        frames = df_meta[\"video_frame\"].values\n",
    "\n",
    "        for action in df_preds.columns: \n",
    "            pred_col = df_preds[action].values \n",
    "            segments = detect_action_segments(frames, pred_col) \n",
    "            \n",
    "            for (start, stop) in segments: # Lấy agent_id/target_id từ df_meta tương ứng với start frame \n",
    "                mask = (df_meta[\"video_frame\"] >= start) & (df_meta[\"video_frame\"] <= stop) \n",
    "                agent_ids = df_meta.loc[mask, \"agent_id\"].unique() \n",
    "                target_ids = df_meta.loc[mask, \"target_id\"].unique() # Nếu single thì agent_id == target_id, nếu pair thì giữ 2 id \n",
    "            \n",
    "                for a_id in agent_ids: \n",
    "                    for t_id in target_ids: \n",
    "                        rows.append([ \n",
    "                            video_id, \n",
    "                            a_id, \n",
    "                            t_id, \n",
    "                            action, \n",
    "                            int(start), \n",
    "                            int(stop) \n",
    "                        ]) \n",
    "                    \n",
    "    submission = pd.DataFrame(rows, columns=[\"video_id\", \"agent_id\", \"target_id\", \"action\", \"start_frame\", \"stop_frame\"]) \n",
    "    submission.insert(0, \"row_id\", range(len(submission))) \n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-25T19:27:43.095Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test = test_csv.copy()\n",
    "test_videos = test[\"video_id\"].unique()\n",
    "\n",
    "submission_list = []\n",
    "\n",
    "for vid in test_videos:\n",
    "    video_rows = test[test[\"video_id\"] == vid]\n",
    "    body_parts_tracked = video_rows[\"body_parts_tracked\"].iloc[0]\n",
    "\n",
    "    # Lấy index section từ body_parts_list (giả sử body_parts_list có sẵn)\n",
    "    try:\n",
    "        section = body_parts_list.index(body_parts_tracked)\n",
    "    except ValueError:\n",
    "        print(f\"Video {vid}: body_parts_tracked not found in body_parts_list, skip\")\n",
    "        continue\n",
    "\n",
    "    # Load model của section tương ứng\n",
    "    section_dir = f\"/kaggle/working/models/{section}\"\n",
    "    single_actions = [f[:-11] for f in os.listdir(f\"{section_dir}/single\") if f.endswith(\"_model.pkl\")]\n",
    "    pair_actions   = [f[:-11] for f in os.listdir(f\"{section_dir}/pair\")   if f.endswith(\"_model.pkl\")]\n",
    "\n",
    "    # Tạo single + pair data cho video test\n",
    "    single_data, pair_data = generate_mouse_data(\n",
    "        video_rows, \n",
    "        \"test\", \n",
    "        drop_body_parts=drop_body_parts\n",
    "    )\n",
    "\n",
    "    # Test từng single mouse\n",
    "    for df_meta, df_feat, _ in single_data:\n",
    "        df_preds = pd.DataFrame(index=df_feat.index)\n",
    "\n",
    "        for action in single_actions:\n",
    "            model_path = f\"{section_dir}/single/{action}_model.pkl\"\n",
    "            thresh_path = f\"{section_dir}/single/{action}_threshold.pkl\"\n",
    "            \n",
    "            clf = joblib.load(model_path)\n",
    "            threshold = joblib.load(thresh_path)\n",
    "            \n",
    "            proba = clf.predict_proba(df_feat.values)[:,1]\n",
    "            preds = (proba >= threshold).astype(int)\n",
    "\n",
    "            df_preds[action] = preds\n",
    "            \n",
    "        submission_list.append((vid, df_meta, df_preds))\n",
    "\n",
    "    # Test từng pair mouse\n",
    "    for df_meta, df_feat, _ in pair_data:\n",
    "        df_preds = pd.DataFrame(index=df_feat.index)\n",
    "\n",
    "        for action in pair_actions:\n",
    "            model_path = f\"{section_dir}/pair/{action}_model.pkl\"\n",
    "            thresh_path = f\"{section_dir}/pair/{action}_threshold.pkl\"\n",
    "            \n",
    "            clf = joblib.load(model_path)\n",
    "            threshold = joblib.load(thresh_path)\n",
    "            \n",
    "            proba = clf.predict_proba(df_feat.values)[:,1]\n",
    "            preds = (proba >= threshold).astype(int)\n",
    "\n",
    "            df_preds[action] = preds\n",
    "            \n",
    "        submission_list.append((vid, df_meta, df_preds))\n",
    "\n",
    "# Tạo submission duy nhất\n",
    "final_submission_rows = []\n",
    "for vid in test_videos:\n",
    "    vid_results = [x for x in submission_list if x[0] == vid]\n",
    "    if len(vid_results) == 0:\n",
    "        continue\n",
    "\n",
    "    submission_df = create_submission(vid_results, vid)\n",
    "    final_submission_rows.append(submission_df)\n",
    "\n",
    "final_submission = pd.concat(final_submission_rows, axis=0, ignore_index=True)\n",
    "    \n",
    "final_submission.to_csv()\n",
    "final_submission"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
